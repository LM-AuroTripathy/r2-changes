{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "2a1162ad",
   "metadata": {},
   "source": [
    "## NOTEBOOK: Profile a ResNet18 Model\n",
    "\n",
    "This tutorial validates, compiles, and profiles a ResNet18 model for inference on Envise using the Idiom Software Stack.\n",
    "\n",
    "Run this Jupyter notebook on an environment that has a GPU instance. \n",
    "\n",
    "The model will traverse through the following stages in the developer flow:\n",
    "\n",
    "**Validate the model**\n",
    "    \n",
    "    The operator coverage tool is invoked at this stage and checks for supported and unsupported ONXX operators in the model. \n",
    "\n",
    "**Compile the model** \n",
    "    \n",
    "    The compile() Idiom API is invoked at this stage and the ONNX model is compiled for Envise.\n",
    "\n",
    "**Profile the model** \n",
    "    \n",
    "    The profile() Idiom API is invoked at this stage and the model is executed at runtime in an Envise-simulated environment for performance metrics.\n",
    "\n",
    "**SYSTEM COMPONENT MINIMUM REQUIREMENTS**\n",
    "\n",
    "* CPU: Any X86-64 architecture with 4 cores\n",
    "* RAM: 64 GB memory\n",
    "* GPU: One Nvidia 2080"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ecc5f8f5",
   "metadata": {},
   "source": [
    "#### Set up Imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "2e7b8f07",
   "metadata": {},
   "outputs": [],
   "source": [
    "import idiom\n",
    "import torch\n",
    "import torchvision\n",
    "import torchvision.datasets as datasets\n",
    "import torchvision.transforms as transforms\n",
    "import itertools"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8888b22a-b893-4192-b821-7643769dd74d",
   "metadata": {},
   "source": [
    "#### Convert file to ONNX\n",
    "Specify the `batch_size` and use the variable where ever the batch size is needed."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "bac73ded-6062-4906-b360-2e221f752712",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torchvision.models as models\n",
    "model = models.resnet18(pretrained=False, num_classes=10)\n",
    "model.load_state_dict(torch.load('/idiom-eap/examples/00-getting-started/resnet-18-imagewoof2-320.pth'))\n",
    "model.eval()\n",
    "onnx_file_name = 'rn18.onnx'\n",
    "batch_size  = 2\n",
    "# Input to the model\n",
    "x = torch.randn(batch_size, 3, 320, 320, requires_grad=True)\n",
    "\n",
    "torch.onnx.export(model,                  # model being run\n",
    "                  x,                      # model input (or a tuple for multiple inputs)\n",
    "                  onnx_file_name,         # where to save the model (can be a file or file-like object)\n",
    "                  verbose=False,\n",
    "                  input_names = ['input'],   # the model's input names\n",
    "                  output_names = ['output'],) # the model's output names\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "06147ffe-7300-4e88-99ee-e6bd5194e393",
   "metadata": {},
   "source": [
    "#### Validate Model\n",
    "\n",
    "The model needs to get validated for Operator Coverage. Here the ONNX model is scanned and you get an output that shows a list of supported and unsupported operations by the compiler.\n",
    "\n",
    "The ONNX file that is being validated is: `resnet-18-imagewoof2-320.onnx`\n",
    "\n",
    "The ``idiom.cc.onnx.check_op_cov`` API command invokes the Operator Coverage functionality. It accepts one argument: an ONNX model.\n",
    " "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "f1080fc6-766a-4870-ab67-2f74defb8800",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2022-08-15 17:16:39,282 - check-op-cov - INFO - check-op-cov v0.5.0\n",
      "Date and time: August 15, 2022 17:16:39\n",
      "Source model path: /idiom-eap/examples/00-getting-started/tutorials/resnet18/perf/rn18.onnx\n",
      "2022-08-15 17:16:39,283 - check-op-cov - INFO - Output files will be saved in /idiom-eap/examples/00-getting-started/tutorials/resnet18/perf/rn18_opcov\n",
      "2022-08-15 17:16:39,284 - check-op-cov - INFO - Running operator coverage tool...\n",
      "2022-08-15 17:16:39,609 - check-op-cov - INFO - Finished running operator coverage tool.\n",
      "2022-08-15 17:16:39,614 - check-op-cov - INFO - General messages from the compiler:\n",
      "ONNX opset version 9\n",
      "ONNX IR version 7\n",
      "ONNX producer \"pytorch\" version 1.10\n",
      "ONNX model version 0\n",
      "\n",
      "2022-08-15 17:16:39,614 - check-op-cov - INFO - 49/49 operators from 7 op types passed. All ops are supported!\n",
      "2022-08-15 17:16:39,616 - check-op-cov - INFO - Op types summary:\n",
      "Op Type            Total          Supported      Unsupported    Failed         \n",
      "-------------------------------------------------------------------------------\n",
      "Add                8              8              0              0              \n",
      "Conv               20             20             0              0              \n",
      "Flatten            1              1              0              0              \n",
      "Gemm               1              1              0              0              \n",
      "GlobalAveragePool  1              1              0              0              \n",
      "MaxPool            1              1              0              0              \n",
      "Relu               17             17             0              0              \n",
      "\n",
      "2022-08-15 17:16:39,617 - check-op-cov - INFO - Visuals not created because all ops are supported.\n"
     ]
    }
   ],
   "source": [
    "from idiom.cc.onnx import check_op_cov\n",
    "check_op_cov(onnx_file_name)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3cb42e2c-0083-42c8-ac53-89c1c1c8758d",
   "metadata": {},
   "source": [
    "Above, you can see that the model is fully supported. Thus, it is suitable for compilation. "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bf7e9408-6e6b-43b2-8a62-586f794da781",
   "metadata": {},
   "source": [
    "#### Compile\n",
    "\n",
    "The ``idiom.cc.onnx.compile`` API command invokes the Idiom Compiler, where an ONNX model is compiled for Envise. It accepts mainly two arguments:\n",
    "\n",
    "* **output_directory** \n",
    "\n",
    "    Directory where the output files will get stored after compilation.\n",
    "\n",
    "* **onnx_file_path**\n",
    "    \n",
    "    Path to the ONNX model."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "8b7f2d91",
   "metadata": {},
   "outputs": [],
   "source": [
    "from idiom.cc.onnx import compile\n",
    "compiled_model_path = 'compiled-onnx'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "f75e8422",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Starting compiling...\n",
      "Done compiling\n"
     ]
    }
   ],
   "source": [
    "print('Starting compiling...')\n",
    "idiom.cc.onnx.compile(compiled_model_path, onnx_file_name, batch_size=batch_size)\n",
    "print('Done compiling')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a5d8c89c-86ef-4f19-b8e2-a729b754b492",
   "metadata": {},
   "source": [
    "#### Get Dataset\n",
    "\n",
    "Get the ImageWoof dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "657b17b7-832f-44b3-8c68-2f2920715270",
   "metadata": {},
   "outputs": [],
   "source": [
    "# !wget https://s3.amazonaws.com/fast-ai-imageclas/imagewoof2-320.tgz"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "a45218f9-970f-400b-ae46-b6a3b949a713",
   "metadata": {},
   "outputs": [],
   "source": [
    "# !tar xf imagewoof2-320.tgz  # silent\n",
    "# !echo \"Done\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "1ce4a54f-111b-4db2-8098-80c1b2d4f87b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "total 1168\n",
      "-rw-r--r--  1 auro auro 1186099 Feb  6  2021 noisy_imagewoof.csv\n",
      "drwxr-xr-x 12 auro auro    4096 Mar  7  2019 train\n",
      "drwxr-xr-x 12 auro auro    4096 Mar  7  2019 val\n"
     ]
    }
   ],
   "source": [
    "!ls -l imagewoof2-320  # check you have the train and validation folders"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1e1bf646-0f16-4ce8-9048-9ef5b84c52d7",
   "metadata": {},
   "source": [
    "#### Load Dataset\n",
    "\n",
    "Load the dataset and initialize the Dataloader features."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "50b48414-e004-44ee-9a85-ad7ced37ad2a",
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_input_data(dataset_path: str):\n",
    "    print('Loading input data')\n",
    "\n",
    "    loader = torch.utils.data.DataLoader(\n",
    "        datasets.ImageFolder(dataset_path, \n",
    "                             transforms.Compose([\n",
    "                                 transforms.Resize((320, 320)),\n",
    "                                 transforms.ToTensor(),\n",
    "                                 transforms.Normalize(mean=[0.485, 0.456, 0.406], std=[0.229, 0.224, 0.225])])),\n",
    "        batch_size=batch_size, \n",
    "        shuffle=False,\n",
    "        num_workers=1, \n",
    "        pin_memory=False)\n",
    "\n",
    "    data = [{'input': x[0].numpy()} for x in itertools.islice(loader, 1)]\n",
    "\n",
    "    return data"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fb534297-1425-4a8a-bd22-e47dc5f1cdd9",
   "metadata": {},
   "source": [
    "\n",
    "#### Profile Model\n",
    "\n",
    "The ``idiom.runtime.profile`` API command invokes the profiler. It measures the modelâ€™s performance metrics such as Inferences Per Second (IPS) and latency of your model for Envise by profiling the execution of the model at runtime. \n",
    "\n",
    "It accepts three arguments:\n",
    "\n",
    "* **Compiled Model Directory**\n",
    "\n",
    "    The Compiled Model Directory where the compilation output resides.\n",
    "\n",
    "* **Input data**\n",
    "\n",
    "    A sequence of dictionaries containing model inputs. \n",
    "\n",
    "* **Batch size**\n",
    "\n",
    "    The number of samples within a batch. This value is used to compute performance metrics.\n",
    "    \n",
    "    Note that we are setting the batch size to **1** in this tutorial. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "17926dd4-cf13-4803-a8f6-9a5492bca0a5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Starting loading & profiling...this may take a few seconds\n",
      "imagewoof2-320\n",
      "Loading input data\n",
      "(2, 3, 320, 320)\n",
      "Profiling compiled-onnx\n",
      "    Loading model\n",
      "    Profiling model execution\n",
      "        Running batch 1 of 1\n",
      "\n",
      "Performance Report\n",
      "\n",
      "Source model path: compiled-onnx\n",
      "Batch size: 2\n",
      "Number of Envises: 0.5\n",
      "\n",
      "+------------------------------------+-------------------------+----------------------+\n",
      "|         Measurement Scope          |   Inferences per Second |   Batch Latency (ms) |\n",
      "+====================================+=========================+======================+\n",
      "|  System Performance (CPU Compute,  |                      53 |                38.04 |\n",
      "| Envise Compute, and Data Transfer) |                         |                      |\n",
      "+------------------------------------+-------------------------+----------------------+\n",
      "|  Envise Compute and Data Transfer  |                    2228 |                 0.9  |\n",
      "+------------------------------------+-------------------------+----------------------+\n",
      "|        Only Envise Compute         |                    3130 |                 0.64 |\n",
      "+------------------------------------+-------------------------+----------------------+\n",
      "|          Only CPU Compute          |                      54 |                37.15 |\n",
      "+------------------------------------+-------------------------+----------------------+\n"
     ]
    }
   ],
   "source": [
    "from idiom.runtime import profile\n",
    "dataset_path = 'imagewoof2-320'\n",
    "print('Starting loading & profiling...this may take a few seconds')\n",
    "input_data = load_input_data(dataset_path)\n",
    "compiled_model_dir = 'compiled-onnx'\n",
    "idiom.runtime.profile(compiled_model_dir, input_data, detailed_report=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "47d91cb3-362b-4380-821a-5ea65ad3858b",
   "metadata": {},
   "source": [
    "#### Conclusion\n",
    "\n",
    "This tutorial shows how to validate, compile, and profile a ``ResNet18`` model, and measure its performance metrics for Envise-behavior.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a6410c54-25ac-4a39-8386-8806f438edf0",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
