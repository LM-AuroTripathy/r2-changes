{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "2a1162ad",
   "metadata": {},
   "source": [
    "## NOTEBOOK: Profile a ResNet18 Model\n",
    "\n",
    "This tutorial validates, compiles, and profiles a ResNet18 model for inference on Envise using the Idiom Software Stack.\n",
    "\n",
    "Run this Jupyter notebook on an environment that has a GPU instance. \n",
    "\n",
    "The model will traverse through the following stages in the developer flow:\n",
    "\n",
    "**Validate the model**\n",
    "    \n",
    "    The operator coverage tool is invoked at this stage and checks for supported and unsupported ONXX operators in the model. \n",
    "\n",
    "**Compile the model** \n",
    "    \n",
    "    The compile() Idiom API is invoked at this stage and the ONNX model is compiled for Envise.\n",
    "\n",
    "**Profile the model** \n",
    "    \n",
    "    The profile() Idiom API is invoked at this stage and the model is executed at runtime in an Envise-simulated environment for performance metrics.\n",
    "\n",
    "**SYSTEM COMPONENT MINIMUM REQUIREMENTS**\n",
    "\n",
    "* CPU: Any X86-64 architecture with 4 cores\n",
    "* RAM: 64 GB memory\n",
    "* GPU: One Nvidia 2080"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ecc5f8f5",
   "metadata": {},
   "source": [
    "#### Set up Imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "2e7b8f07",
   "metadata": {},
   "outputs": [],
   "source": [
    "import idiom\n",
    "import torch\n",
    "import torchvision\n",
    "import torchvision.datasets as datasets\n",
    "import torchvision.transforms as transforms\n",
    "import itertools"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8888b22a-b893-4192-b821-7643769dd74d",
   "metadata": {},
   "source": [
    "#### Convert file to ONNX\n",
    "Specify the `batch_size` and use the variable where ever the batch size is needed."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "bac73ded-6062-4906-b360-2e221f752712",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torchvision.models as models\n",
    "model = models.resnet18(pretrained=False, num_classes=10)\n",
    "model.load_state_dict(torch.load('/idiom-eap/examples/00-getting-started/resnet-18-imagewoof2-320.pth'))\n",
    "model.eval()\n",
    "onnx_file_name = 'rn18.onnx'\n",
    "batch_size  = 2\n",
    "# Input to the model\n",
    "x = torch.randn(batch_size, 3, 320, 320, requires_grad=True)\n",
    "\n",
    "torch.onnx.export(model,                  # model being run\n",
    "                  x,                      # model input (or a tuple for multiple inputs)\n",
    "                  onnx_file_name,         # where to save the model (can be a file or file-like object)\n",
    "                  verbose=False,\n",
    "                  input_names = ['input'],   # the model's input names\n",
    "                  output_names = ['output'],) # the model's output names\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "06147ffe-7300-4e88-99ee-e6bd5194e393",
   "metadata": {},
   "source": [
    "#### Validate Model\n",
    "\n",
    "The model needs to get validated for Operator Coverage. Here the ONNX model is scanned and you get an output that shows a list of supported and unsupported operations by the compiler.\n",
    "\n",
    "The ONNX file that is being validated is: `resnet-18-imagewoof2-320.onnx`\n",
    "\n",
    "The ``idiom.cc.onnx.check_op_cov`` API command invokes the Operator Coverage functionality. It accepts one argument: an ONNX model.\n",
    " "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "f1080fc6-766a-4870-ab67-2f74defb8800",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2022-08-15 17:16:39,282 - check-op-cov - INFO - check-op-cov v0.5.0\n",
      "Date and time: August 15, 2022 17:16:39\n",
      "Source model path: /idiom-eap/examples/00-getting-started/tutorials/resnet18/perf/rn18.onnx\n",
      "2022-08-15 17:16:39,283 - check-op-cov - INFO - Output files will be saved in /idiom-eap/examples/00-getting-started/tutorials/resnet18/perf/rn18_opcov\n",
      "2022-08-15 17:16:39,284 - check-op-cov - INFO - Running operator coverage tool...\n",
      "2022-08-15 17:16:39,609 - check-op-cov - INFO - Finished running operator coverage tool.\n",
      "2022-08-15 17:16:39,614 - check-op-cov - INFO - General messages from the compiler:\n",
      "ONNX opset version 9\n",
      "ONNX IR version 7\n",
      "ONNX producer \"pytorch\" version 1.10\n",
      "ONNX model version 0\n",
      "\n",
      "2022-08-15 17:16:39,614 - check-op-cov - INFO - 49/49 operators from 7 op types passed. All ops are supported!\n",
      "2022-08-15 17:16:39,616 - check-op-cov - INFO - Op types summary:\n",
      "Op Type            Total          Supported      Unsupported    Failed         \n",
      "-------------------------------------------------------------------------------\n",
      "Add                8              8              0              0              \n",
      "Conv               20             20             0              0              \n",
      "Flatten            1              1              0              0              \n",
      "Gemm               1              1              0              0              \n",
      "GlobalAveragePool  1              1              0              0              \n",
      "MaxPool            1              1              0              0              \n",
      "Relu               17             17             0              0              \n",
      "\n",
      "2022-08-15 17:16:39,617 - check-op-cov - INFO - Visuals not created because all ops are supported.\n"
     ]
    }
   ],
   "source": [
    "from idiom.cc.onnx import check_op_cov\n",
    "check_op_cov(onnx_file_name)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3cb42e2c-0083-42c8-ac53-89c1c1c8758d",
   "metadata": {},
   "source": [
    "Above, you can see that the model is fully supported. Thus, it is suitable for compilation. "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bf7e9408-6e6b-43b2-8a62-586f794da781",
   "metadata": {},
   "source": [
    "#### Compile\n",
    "\n",
    "The ``idiom.cc.onnx.compile`` API command invokes the Idiom Compiler, where an ONNX model is compiled for Envise. It accepts mainly two arguments:\n",
    "\n",
    "* **output_directory** \n",
    "\n",
    "    Directory where the output files will get stored after compilation.\n",
    "\n",
    "* **onnx_file_path**\n",
    "    \n",
    "    Path to the ONNX model."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "8b7f2d91",
   "metadata": {},
   "outputs": [],
   "source": [
    "from idiom.cc.onnx import compile\n",
    "compiled_model_path = 'compiled-onnx'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "f75e8422",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Starting compiling...\n",
      "Done compiling\n"
     ]
    }
   ],
   "source": [
    "print('Starting compiling...')\n",
    "idiom.cc.onnx.compile(compiled_model_path, onnx_file_name, batch_size=batch_size)\n",
    "print('Done compiling')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a5d8c89c-86ef-4f19-b8e2-a729b754b492",
   "metadata": {},
   "source": [
    "#### Get Dataset\n",
    "\n",
    "Get the ImageWoof dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "657b17b7-832f-44b3-8c68-2f2920715270",
   "metadata": {},
   "outputs": [],
   "source": [
    "# !wget https://s3.amazonaws.com/fast-ai-imageclas/imagewoof2-320.tgz"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "a45218f9-970f-400b-ae46-b6a3b949a713",
   "metadata": {},
   "outputs": [],
   "source": [
    "# !tar xf imagewoof2-320.tgz  # silent\n",
    "# !echo \"Done\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "1ce4a54f-111b-4db2-8098-80c1b2d4f87b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "total 1168\n",
      "-rw-r--r--  1 auro auro 1186099 Feb  6  2021 noisy_imagewoof.csv\n",
      "drwxr-xr-x 12 auro auro    4096 Mar  7  2019 train\n",
      "drwxr-xr-x 12 auro auro    4096 Mar  7  2019 val\n"
     ]
    }
   ],
   "source": [
    "!ls -l imagewoof2-320  # check you have the train and validation folders"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1e1bf646-0f16-4ce8-9048-9ef5b84c52d7",
   "metadata": {},
   "source": [
    "#### Load Dataset\n",
    "\n",
    "Load the dataset and initialize the Dataloader features."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "50b48414-e004-44ee-9a85-ad7ced37ad2a",
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_input_data(dataset_path: str):\n",
    "    print('Loading input data')\n",
    "\n",
    "    loader = torch.utils.data.DataLoader(\n",
    "        datasets.ImageFolder(dataset_path, \n",
    "                             transforms.Compose([\n",
    "                                 transforms.Resize((320, 320)),\n",
    "                                 transforms.ToTensor(),\n",
    "                                 transforms.Normalize(mean=[0.485, 0.456, 0.406], std=[0.229, 0.224, 0.225])])),\n",
    "        batch_size=batch_size, \n",
    "        shuffle=False,\n",
    "        num_workers=1, \n",
    "        pin_memory=False)\n",
    "\n",
    "    data = [{'input': x[0].numpy()} for x in itertools.islice(loader, 1)]\n",
    "\n",
    "    return data"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fb534297-1425-4a8a-bd22-e47dc5f1cdd9",
   "metadata": {},
   "source": [
    "\n",
    "#### Profile Model\n",
    "\n",
    "The ``idiom.runtime.profile`` API command invokes the profiler. It measures the model’s performance metrics such as Inferences Per Second (IPS) and latency of your model for Envise by profiling the execution of the model at runtime. \n",
    "\n",
    "It accepts three arguments:\n",
    "\n",
    "* **Compiled Model Directory**\n",
    "\n",
    "    The Compiled Model Directory where the compilation output resides.\n",
    "\n",
    "* **Input data**\n",
    "\n",
    "    A sequence of dictionaries containing model inputs. \n",
    "\n",
    "* **Batch size**\n",
    "\n",
    "    The number of samples within a batch. This value is used to compute performance metrics.\n",
    "    \n",
    "    Note that we are setting the batch size to **1** in this tutorial. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "17926dd4-cf13-4803-a8f6-9a5492bca0a5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Starting loading & profiling...this may take a few seconds\n",
      "imagewoof2-320\n",
      "Loading input data\n",
      "(2, 3, 320, 320)\n",
      "Profiling compiled-onnx\n",
      "    Loading model\n",
      "    Profiling model execution\n",
      "        Running batch 1 of 1\n",
      "\n",
      "Performance Report\n",
      "\n",
      "Source model path: compiled-onnx\n",
      "Batch size: 2\n",
      "Number of Envises: 0.5\n",
      "\n",
      "+------------------------------------+-------------------------+----------------------+\n",
      "|         Measurement Scope          |   Inferences per Second |   Batch Latency (ms) |\n",
      "+====================================+=========================+======================+\n",
      "|  System Performance (CPU Compute,  |                      53 |                38.04 |\n",
      "| Envise Compute, and Data Transfer) |                         |                      |\n",
      "+------------------------------------+-------------------------+----------------------+\n",
      "|  Envise Compute and Data Transfer  |                    2228 |                 0.9  |\n",
      "+------------------------------------+-------------------------+----------------------+\n",
      "|        Only Envise Compute         |                    3130 |                 0.64 |\n",
      "+------------------------------------+-------------------------+----------------------+\n",
      "|          Only CPU Compute          |                      54 |                37.15 |\n",
      "+------------------------------------+-------------------------+----------------------+\n"
     ]
    }
   ],
   "source": [
    "from idiom.runtime import profile\n",
    "dataset_path = 'imagewoof2-320'\n",
    "print('Starting loading & profiling...this may take a few seconds')\n",
    "input_data = load_input_data(dataset_path)\n",
    "compiled_model_dir = 'compiled-onnx'\n",
    "idiom.runtime.profile(compiled_model_dir, input_data, detailed_report=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "47d91cb3-362b-4380-821a-5ea65ad3858b",
   "metadata": {},
   "source": [
    "#### Conclusion\n",
    "\n",
    "This tutorial shows how to validate, compile, and profile a ``ResNet18`` model, and measure its performance metrics for Envise-behavior.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a6410c54-25ac-4a39-8386-8806f438edf0",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
