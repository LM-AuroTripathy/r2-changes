{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "2a1162ad",
   "metadata": {
    "tags": []
   },
   "source": [
    "## NOTEBOOK: Profile a BERT-Tiny Model\n",
    "\n",
    "This tutorial validates, compiles, and profiles a Bert-Tiny model for inference on Envise using the Idiom Software Stack.\n",
    "\n",
    "The model we're going to be working with is, [mrm8488/bert-tiny-finetuned-squadv2](https://huggingface.co/mrm8488/bert-tiny-finetuned-squadv2). You can find more about this model on Hugging Face.\n",
    "\n",
    "Run this Jupyter notebook on an environment that has a GPU instance. \n",
    "\n",
    "The model will traverse through the following stages in the developer flow:\n",
    "\n",
    "**Export model to ONNX**\n",
    "    \n",
    "    The original model is exported to ONNX before validating operator coverage. \n",
    "\n",
    "**Validate the model**\n",
    "    \n",
    "    The operator coverage tool is invoked at this stage and checks for supported and unsupported ONXX operators in the model. \n",
    "\n",
    "**Compile the model** \n",
    "    \n",
    "    The compile() Idiom API is invoked at this stage and the ONNX model is compiled for Envise.\n",
    "\n",
    "**Profile the model** \n",
    "    \n",
    "    The profile() Idiom API is invoked at this stage and the model is executed at runtime in an Envise-simulated environment for performance metrics.\n",
    "\n",
    "**SYSTEM COMPONENT MINIMUM REQUIREMENTS**\n",
    "\n",
    "* CPU: Any X86-64 architecture with 4 cores\n",
    "* RAM: 64 GB memory\n",
    "* GPU: One Nvidia 2080"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f6d3954e-1478-4464-b71e-650fbd744718",
   "metadata": {},
   "source": [
    "#### Install Dependencies\n",
    "This step takes under one minute"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "5a197f48-4541-4f8a-80db-e699fbf0c0ad",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: psutil in /opt/venv/lib/python3.8/site-packages (from -r requirements.txt (line 1)) (5.9.1)\n",
      "Collecting accelerate==0.5.1\n",
      "  Downloading accelerate-0.5.1-py3-none-any.whl (58 kB)\n",
      "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m58.0/58.0 kB\u001b[0m \u001b[31m11.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hCollecting datasets==1.18.3\n",
      "  Downloading datasets-1.18.3-py3-none-any.whl (311 kB)\n",
      "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m311.7/311.7 kB\u001b[0m \u001b[31m32.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hCollecting transformers[onnx]==4.16.2\n",
      "  Downloading transformers-4.16.2-py3-none-any.whl (3.5 MB)\n",
      "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m3.5/3.5 MB\u001b[0m \u001b[31m21.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m00:01\u001b[0m00:01\u001b[0m\n",
      "\u001b[?25hRequirement already satisfied: torch>=1.4.0 in /opt/venv/lib/python3.8/site-packages (from accelerate==0.5.1->-r requirements.txt (line 2)) (1.10.0+cu111)\n",
      "Requirement already satisfied: pyyaml in /opt/venv/lib/python3.8/site-packages (from accelerate==0.5.1->-r requirements.txt (line 2)) (6.0)\n",
      "Requirement already satisfied: numpy>=1.17 in /opt/venv/lib/python3.8/site-packages (from accelerate==0.5.1->-r requirements.txt (line 2)) (1.23.2)\n",
      "Collecting pandas\n",
      "  Downloading pandas-1.4.3-cp38-cp38-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (11.7 MB)\n",
      "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m11.7/11.7 MB\u001b[0m \u001b[31m11.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m00:01\u001b[0m00:01\u001b[0m\n",
      "\u001b[?25hRequirement already satisfied: packaging in /opt/venv/lib/python3.8/site-packages (from datasets==1.18.3->-r requirements.txt (line 3)) (21.3)\n",
      "Collecting dill\n",
      "  Downloading dill-0.3.5.1-py2.py3-none-any.whl (95 kB)\n",
      "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m95.8/95.8 kB\u001b[0m \u001b[31m10.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hCollecting multiprocess\n",
      "  Downloading multiprocess-0.70.13-py38-none-any.whl (131 kB)\n",
      "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m131.4/131.4 kB\u001b[0m \u001b[31m12.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hCollecting xxhash\n",
      "  Downloading xxhash-3.0.0-cp38-cp38-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (212 kB)\n",
      "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m212.1/212.1 kB\u001b[0m \u001b[31m15.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hCollecting aiohttp\n",
      "  Downloading aiohttp-3.8.1-cp38-cp38-manylinux_2_5_x86_64.manylinux1_x86_64.manylinux_2_12_x86_64.manylinux2010_x86_64.whl (1.3 MB)\n",
      "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m1.3/1.3 MB\u001b[0m \u001b[31m25.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0ma \u001b[36m0:00:01\u001b[0m\n",
      "\u001b[?25hRequirement already satisfied: huggingface-hub<1.0.0,>=0.1.0 in /opt/venv/lib/python3.8/site-packages (from datasets==1.18.3->-r requirements.txt (line 3)) (0.8.1)\n",
      "Collecting pyarrow!=4.0.0,>=3.0.0\n",
      "  Downloading pyarrow-9.0.0-cp38-cp38-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (35.3 MB)\n",
      "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m35.3/35.3 MB\u001b[0m \u001b[31m9.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m:00:01\u001b[0m00:01\u001b[0m\n",
      "\u001b[?25hCollecting fsspec[http]>=2021.05.0\n",
      "  Downloading fsspec-2022.7.1-py3-none-any.whl (141 kB)\n",
      "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m141.2/141.2 kB\u001b[0m \u001b[31m13.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hRequirement already satisfied: requests>=2.19.0 in /opt/venv/lib/python3.8/site-packages (from datasets==1.18.3->-r requirements.txt (line 3)) (2.28.1)\n",
      "Requirement already satisfied: tqdm>=4.62.1 in /opt/venv/lib/python3.8/site-packages (from datasets==1.18.3->-r requirements.txt (line 3)) (4.64.0)\n",
      "Requirement already satisfied: tokenizers!=0.11.3,>=0.10.1 in /opt/venv/lib/python3.8/site-packages (from transformers[onnx]==4.16.2->-r requirements.txt (line 4)) (0.12.1)\n",
      "Collecting sacremoses\n",
      "  Downloading sacremoses-0.0.53.tar.gz (880 kB)\n",
      "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m880.6/880.6 kB\u001b[0m \u001b[31m18.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0ma \u001b[36m0:00:01\u001b[0m\n",
      "\u001b[?25h  Preparing metadata (setup.py) ... \u001b[?25ldone\n",
      "\u001b[?25hRequirement already satisfied: filelock in /opt/venv/lib/python3.8/site-packages (from transformers[onnx]==4.16.2->-r requirements.txt (line 4)) (3.8.0)\n",
      "Requirement already satisfied: regex!=2019.12.17 in /opt/venv/lib/python3.8/site-packages (from transformers[onnx]==4.16.2->-r requirements.txt (line 4)) (2022.7.25)\n",
      "Collecting onnxruntime-tools>=1.4.2\n",
      "  Downloading onnxruntime_tools-1.7.0-py3-none-any.whl (212 kB)\n",
      "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m212.7/212.7 kB\u001b[0m \u001b[31m11.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hCollecting onnxruntime>=1.4.0\n",
      "  Downloading onnxruntime-1.12.1-cp38-cp38-manylinux_2_27_x86_64.whl (4.9 MB)\n",
      "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m4.9/4.9 MB\u001b[0m \u001b[31m12.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m00:01\u001b[0m00:01\u001b[0m\n",
      "\u001b[?25hCollecting tf2onnx\n",
      "  Downloading tf2onnx-1.12.0-py3-none-any.whl (442 kB)\n",
      "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m442.0/442.0 kB\u001b[0m \u001b[31m18.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hCollecting onnxconverter-common\n",
      "  Downloading onnxconverter_common-1.12.1-py2.py3-none-any.whl (83 kB)\n",
      "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m83.6/83.6 kB\u001b[0m \u001b[31m14.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hRequirement already satisfied: typing-extensions>=3.7.4.3 in /opt/venv/lib/python3.8/site-packages (from huggingface-hub<1.0.0,>=0.1.0->datasets==1.18.3->-r requirements.txt (line 3)) (4.3.0)\n",
      "Requirement already satisfied: protobuf in /opt/venv/lib/python3.8/site-packages (from onnxruntime>=1.4.0->transformers[onnx]==4.16.2->-r requirements.txt (line 4)) (3.20.1)\n",
      "Collecting sympy\n",
      "  Downloading sympy-1.10.1-py3-none-any.whl (6.4 MB)\n",
      "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m6.4/6.4 MB\u001b[0m \u001b[31m10.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m00:01\u001b[0m00:01\u001b[0m\n",
      "\u001b[?25hCollecting coloredlogs\n",
      "  Downloading coloredlogs-15.0.1-py2.py3-none-any.whl (46 kB)\n",
      "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m46.0/46.0 kB\u001b[0m \u001b[31m3.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hCollecting flatbuffers\n",
      "  Downloading flatbuffers-2.0-py2.py3-none-any.whl (26 kB)\n",
      "Collecting py3nvml\n",
      "  Downloading py3nvml-0.2.7-py3-none-any.whl (55 kB)\n",
      "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m55.5/55.5 kB\u001b[0m \u001b[31m8.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hRequirement already satisfied: onnx in /opt/venv/lib/python3.8/site-packages (from onnxruntime-tools>=1.4.2->transformers[onnx]==4.16.2->-r requirements.txt (line 4)) (1.12.0)\n",
      "Collecting py-cpuinfo\n",
      "  Downloading py-cpuinfo-8.0.0.tar.gz (99 kB)\n",
      "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m99.8/99.8 kB\u001b[0m \u001b[31m11.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25h  Preparing metadata (setup.py) ... \u001b[?25ldone\n",
      "\u001b[?25hRequirement already satisfied: pyparsing!=3.0.5,>=2.0.2 in /opt/venv/lib/python3.8/site-packages (from packaging->datasets==1.18.3->-r requirements.txt (line 3)) (2.4.7)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in /opt/venv/lib/python3.8/site-packages (from requests>=2.19.0->datasets==1.18.3->-r requirements.txt (line 3)) (2022.6.15)\n",
      "Requirement already satisfied: charset-normalizer<3,>=2 in /opt/venv/lib/python3.8/site-packages (from requests>=2.19.0->datasets==1.18.3->-r requirements.txt (line 3)) (2.1.0)\n",
      "Requirement already satisfied: urllib3<1.27,>=1.21.1 in /opt/venv/lib/python3.8/site-packages (from requests>=2.19.0->datasets==1.18.3->-r requirements.txt (line 3)) (1.26.11)\n",
      "Requirement already satisfied: idna<4,>=2.5 in /opt/venv/lib/python3.8/site-packages (from requests>=2.19.0->datasets==1.18.3->-r requirements.txt (line 3)) (3.3)\n",
      "Collecting yarl<2.0,>=1.0\n",
      "  Downloading yarl-1.8.1-cp38-cp38-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (262 kB)\n",
      "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m262.1/262.1 kB\u001b[0m \u001b[31m16.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hRequirement already satisfied: attrs>=17.3.0 in /opt/venv/lib/python3.8/site-packages (from aiohttp->datasets==1.18.3->-r requirements.txt (line 3)) (22.1.0)\n",
      "Collecting async-timeout<5.0,>=4.0.0a3\n",
      "  Downloading async_timeout-4.0.2-py3-none-any.whl (5.8 kB)\n",
      "Collecting aiosignal>=1.1.2\n",
      "  Downloading aiosignal-1.2.0-py3-none-any.whl (8.2 kB)\n",
      "Collecting frozenlist>=1.1.1\n",
      "  Downloading frozenlist-1.3.1-cp38-cp38-manylinux_2_5_x86_64.manylinux1_x86_64.manylinux_2_17_x86_64.manylinux2014_x86_64.whl (161 kB)\n",
      "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m161.3/161.3 kB\u001b[0m \u001b[31m17.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hCollecting multidict<7.0,>=4.5\n",
      "  Downloading multidict-6.0.2-cp38-cp38-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (121 kB)\n",
      "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m121.3/121.3 kB\u001b[0m \u001b[31m16.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hRequirement already satisfied: python-dateutil>=2.8.1 in /opt/venv/lib/python3.8/site-packages (from pandas->datasets==1.18.3->-r requirements.txt (line 3)) (2.8.2)\n",
      "Requirement already satisfied: pytz>=2020.1 in /opt/venv/lib/python3.8/site-packages (from pandas->datasets==1.18.3->-r requirements.txt (line 3)) (2022.2.1)\n",
      "Requirement already satisfied: six in /opt/venv/lib/python3.8/site-packages (from sacremoses->transformers[onnx]==4.16.2->-r requirements.txt (line 4)) (1.16.0)\n",
      "Collecting click\n",
      "  Downloading click-8.1.3-py3-none-any.whl (96 kB)\n",
      "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m96.6/96.6 kB\u001b[0m \u001b[31m15.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hCollecting joblib\n",
      "  Downloading joblib-1.1.0-py2.py3-none-any.whl (306 kB)\n",
      "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m307.0/307.0 kB\u001b[0m \u001b[31m22.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hCollecting flatbuffers\n",
      "  Downloading flatbuffers-1.12-py2.py3-none-any.whl (15 kB)\n",
      "Collecting humanfriendly>=9.1\n",
      "  Downloading humanfriendly-10.0-py2.py3-none-any.whl (86 kB)\n",
      "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m86.8/86.8 kB\u001b[0m \u001b[31m17.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hCollecting xmltodict\n",
      "  Downloading xmltodict-0.13.0-py2.py3-none-any.whl (10.0 kB)\n",
      "Collecting mpmath>=0.19\n",
      "  Downloading mpmath-1.2.1-py3-none-any.whl (532 kB)\n",
      "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m532.6/532.6 kB\u001b[0m \u001b[31m26.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hUsing legacy 'setup.py install' for sacremoses, since package 'wheel' is not installed.\n",
      "Using legacy 'setup.py install' for py-cpuinfo, since package 'wheel' is not installed.\n",
      "Installing collected packages: py-cpuinfo, mpmath, flatbuffers, xxhash, xmltodict, sympy, pyarrow, multidict, joblib, humanfriendly, fsspec, frozenlist, dill, click, async-timeout, yarl, tf2onnx, sacremoses, py3nvml, pandas, onnxconverter-common, multiprocess, coloredlogs, aiosignal, accelerate, transformers, onnxruntime-tools, onnxruntime, aiohttp, datasets\n",
      "  Running setup.py install for py-cpuinfo ... \u001b[?25ldone\n",
      "\u001b[?25h  Running setup.py install for sacremoses ... \u001b[?25ldone\n",
      "\u001b[?25h  Attempting uninstall: transformers\n",
      "    Found existing installation: transformers 4.21.1\n",
      "    Uninstalling transformers-4.21.1:\n",
      "      Successfully uninstalled transformers-4.21.1\n",
      "Successfully installed accelerate-0.5.1 aiohttp-3.8.1 aiosignal-1.2.0 async-timeout-4.0.2 click-8.1.3 coloredlogs-15.0.1 datasets-1.18.3 dill-0.3.5.1 flatbuffers-1.12 frozenlist-1.3.1 fsspec-2022.7.1 humanfriendly-10.0 joblib-1.1.0 mpmath-1.2.1 multidict-6.0.2 multiprocess-0.70.13 onnxconverter-common-1.12.1 onnxruntime-1.12.1 onnxruntime-tools-1.7.0 pandas-1.4.3 py-cpuinfo-8.0.0 py3nvml-0.2.7 pyarrow-9.0.0 sacremoses-0.0.53 sympy-1.10.1 tf2onnx-1.12.0 transformers-4.16.2 xmltodict-0.13.0 xxhash-3.0.0 yarl-1.8.1\n"
     ]
    }
   ],
   "source": [
    "!pip install -r requirements.txt"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9d3a96e5-fbb1-4265-a8c2-3ec94dda953e",
   "metadata": {},
   "source": [
    "#### Set up Imports "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "2e7b8f07",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/venv/lib/python3.8/site-packages/tqdm/auto.py:22: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    }
   ],
   "source": [
    "# Standard imports\n",
    "import os\n",
    "import sys\n",
    "import argparse\n",
    "\n",
    "import numpy as np\n",
    "from pathlib import Path\n",
    "from typing import Mapping\n",
    "from collections import OrderedDict\n",
    "\n",
    "# HuggingFace imports\n",
    "import datasets\n",
    "from transformers.onnx.convert import export\n",
    "from transformers.onnx.config import OnnxConfig\n",
    "from transformers import BertForQuestionAnswering, BertTokenizer\n",
    "\n",
    "# Lightmatter imports\n",
    "import idiom"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ebf75e42-de47-4a53-8c8b-2a856d076016",
   "metadata": {},
   "source": [
    "#### Define Inputs and Outputs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "8b7f2d91",
   "metadata": {},
   "outputs": [],
   "source": [
    "# OnnxConfig is an abstract class, so we need a concrete base class that\n",
    "# provides a name for each tensor & their dimensions. These names are\n",
    "# emitted into the ONNX file.\n",
    "class BertOnnxConfig(OnnxConfig):\n",
    "    def __init__(self, config, task):\n",
    "        super().__init__(config,task)\n",
    "\n",
    "    @property\n",
    "    def inputs(self) -> Mapping[str, Mapping[int, str]]:\n",
    "        return OrderedDict(\n",
    "            {\n",
    "                \"input_ids\":      {0: \"batch\", 1: \"sequence\"},\n",
    "                \"attention_mask\": {0: \"batch\", 1: \"sequence\"},\n",
    "                \"token_type_ids\": {0: \"batch\", 1: \"sequence\"}\n",
    "            }\n",
    "        )\n",
    "\n",
    "    @property\n",
    "    def outputs(self) -> Mapping[str, Mapping[int, str]]:\n",
    "        return OrderedDict(\n",
    "            {\n",
    "                \"start_logits\": {0: \"batch\", 1: \"sequence\"},\n",
    "                \"end_logits\":   {0: \"batch\", 1: \"sequence\"}\n",
    "            }\n",
    "        )"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "18aaa63d-9414-4f4b-b152-c7d1cfaba7fa",
   "metadata": {},
   "source": [
    "#### Define a Function to Encode Inputs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "291a26c8-ea3d-4062-accb-28ea4da21036",
   "metadata": {},
   "outputs": [],
   "source": [
    "def encode_batch(tokenizer, questions, contexts, seq_len):\n",
    "    '''\n",
    "    Calls tokenizer.encode_plus() for each given question+context pair. All\n",
    "    samples are encoded to length <seq_len>; shorter inputs are zero-padded\n",
    "    and longer inputs are truncated.\n",
    "\n",
    "    Params:\n",
    "        tokenizer:             Tokenizer to use for encoding\n",
    "        questions (list[str]): Set of questions\n",
    "        contexts  (list[str]): Set of contexts (length must match questions)\n",
    "        seq_len (int):         Fixed length of encoded samples\n",
    "\n",
    "    Returns: Dictionary of [batch_size x seq_len] tensors (np.array) for\n",
    "        token IDs, segment IDs, and attention masks.\n",
    "    '''\n",
    "\n",
    "    input_ids = []\n",
    "    tkn_types = []\n",
    "    attn_mask = []\n",
    "\n",
    "    for q,c in zip(questions,contexts):\n",
    "        inputs = tokenizer.encode_plus(q,c,return_tensors='np',truncation=True,padding='max_length',max_length=seq_len)\n",
    "        input_ids.append(inputs['input_ids'])\n",
    "        tkn_types.append(inputs['token_type_ids'])\n",
    "        attn_mask.append(inputs['attention_mask'])\n",
    "\n",
    "    input_ids = np.vstack(input_ids)\n",
    "    tkn_types = np.vstack(tkn_types)\n",
    "    attn_mask = np.vstack(attn_mask)\n",
    "\n",
    "    return {\n",
    "        'input_ids' : input_ids,\n",
    "        'token_type_ids' : tkn_types,\n",
    "        'attention_mask' : attn_mask\n",
    "    }\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a5d8c89c-86ef-4f19-b8e2-a729b754b492",
   "metadata": {},
   "source": [
    "#### Initialize the Profiling Parameters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "94cdbfa7-9334-4e32-88d1-9025fe0fdca4",
   "metadata": {},
   "outputs": [],
   "source": [
    "num_batches = 1\n",
    "batch_size = 2\n",
    "sequence_length = 384"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a47d8238-e509-4173-b362-28e901664436",
   "metadata": {},
   "source": [
    "#### Download Model Parameters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "b0c5b727-a0aa-49f3-bfde-506052b20efe",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Downloading model parameters...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Downloading: 100%|█████████████████████████████████████████████████████████████████| 462/462 [00:00<00:00, 330kB/s]\n",
      "Downloading: 100%|████████████████████████████████████████████████████████████| 16.7M/16.7M [00:01<00:00, 13.1MB/s]\n",
      "Downloading: 100%|██████████████████████████████████████████████████████████████| 24.0/24.0 [00:00<00:00, 21.8kB/s]\n",
      "Downloading: 100%|██████████████████████████████████████████████████████████████| 226k/226k [00:00<00:00, 4.36MB/s]\n",
      "Downloading: 100%|█████████████████████████████████████████████████████████████████| 112/112 [00:00<00:00, 196kB/s]\n"
     ]
    }
   ],
   "source": [
    "compile_dir = f'compiled_tiny_bert'\n",
    "onnx_file = compile_dir + '/model.onnx'\n",
    "\n",
    "os.makedirs(compile_dir,exist_ok=True)\n",
    "\n",
    "\n",
    "hf_model_name = 'mrm8488/bert-tiny-finetuned-squadv2'\n",
    "\n",
    "print('Downloading model parameters...')\n",
    "model     = BertForQuestionAnswering.from_pretrained(hf_model_name).eval()\n",
    "tokenizer = BertTokenizer.from_pretrained(hf_model_name)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b2713296-94c3-46d9-a682-1dec525ff679",
   "metadata": {},
   "source": [
    "#### Get Dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "0e574ddc-97fa-423d-a767-585090fe0974",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Downloading SQUADv2 dataset...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Downloading: 5.28kB [00:00, 3.63MB/s]                                                                              \n",
      "Downloading: 2.40kB [00:00, 1.40MB/s]                                                                              \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Downloading and preparing dataset squad_v2/squad_v2 (download: 44.34 MiB, generated: 122.41 MiB, post-processed: Unknown size, total: 166.75 MiB) to /home/auro/.cache/huggingface/datasets/squad_v2/squad_v2/2.0.0/09187c73c1b837c95d9a249cd97c2c3f1cebada06efe667b4427714b27639b1d...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|                                                                                        | 0/2 [00:00<?, ?it/s]\n",
      "Downloading:   0%|                                                                     | 0.00/9.55M [00:00<?, ?B/s]\u001b[A\n",
      "Downloading: 12.9MB [00:00, 129MB/s]                                                                               \u001b[A\n",
      "Downloading: 25.8MB [00:00, 72.1MB/s]\u001b[A\n",
      "Downloading: 34.3MB [00:00, 63.2MB/s]\u001b[A\n",
      "Downloading: 42.1MB [00:00, 64.1MB/s]\u001b[A\n",
      " 50%|████████████████████████████████████████                                        | 1/2 [00:01<00:01,  1.55s/it]\n",
      "Downloading: 4.37MB [00:00, 143MB/s]                                                                               \u001b[A\n",
      "100%|████████████████████████████████████████████████████████████████████████████████| 2/2 [00:01<00:00,  1.17it/s]\n",
      "100%|██████████████████████████████████████████████████████████████████████████████| 2/2 [00:00<00:00, 1611.95it/s]\n",
      "                                            \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Dataset squad_v2 downloaded and prepared to /home/auro/.cache/huggingface/datasets/squad_v2/squad_v2/2.0.0/09187c73c1b837c95d9a249cd97c2c3f1cebada06efe667b4427714b27639b1d. Subsequent calls will reuse this data.\n"
     ]
    }
   ],
   "source": [
    "# Download dataset from HuggingFace hub\n",
    "print('Downloading SQUADv2 dataset...')\n",
    "squad = datasets.load_dataset('squad_v2', split='validation')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "02f734af-7624-4113-9924-806cbdd3d3ba",
   "metadata": {},
   "source": [
    "#### Encode Inputs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "1ce4a54f-111b-4db2-8098-80c1b2d4f87b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Encoding inputs...\n"
     ]
    }
   ],
   "source": [
    "# Encode plain-text paragraphs & questions into token IDs, segment IDs, and attention masks\n",
    "batches = []\n",
    "print('Encoding inputs...')\n",
    "\n",
    "for i in range(num_batches):\n",
    "    batch = list(squad)[i*batch_size:(i+1)*batch_size]\n",
    "    questions = [q['question'] for q in batch]\n",
    "    contexts  = [q['context']  for q in batch]\n",
    "    encoded_inputs = encode_batch(tokenizer,questions,contexts,sequence_length)\n",
    "    batches.append(encoded_inputs)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1e1bf646-0f16-4ce8-9048-9ef5b84c52d7",
   "metadata": {},
   "source": [
    "#### Export the Model to ONNX"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "50b48414-e004-44ee-9a85-ad7ced37ad2a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Exporting model to ONNX...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/venv/lib/python3.8/site-packages/torch/onnx/utils.py:90: UserWarning: 'enable_onnx_checker' is deprecated and ignored. It will be removed in the next PyTorch release. To proceed despite ONNX checker failures, catch torch.onnx.ONNXCheckerError.\n",
      "  warnings.warn(\"'enable_onnx_checker' is deprecated and ignored. It will be removed in \"\n",
      "/opt/venv/lib/python3.8/site-packages/torch/onnx/utils.py:103: UserWarning: `use_external_data_format' is deprecated and ignored. Will be removed in next PyTorch release. The code will work as it is False if models are not larger than 2GB, Otherwise set to False because of size limits imposed by Protocol Buffers.\n",
      "  warnings.warn(\"`use_external_data_format' is deprecated and ignored. Will be removed in next \"\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "(['input_ids', 'attention_mask', 'token_type_ids'],\n",
       " ['start_logits', 'end_logits'])"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "print('Exporting model to ONNX...')\n",
    "config = BertOnnxConfig(model.config, task='question-answering')\n",
    "export(tokenizer,model,config,opset=12,output=Path(onnx_file))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "60f1bfa2-158f-4f27-a256-38280e32bb21",
   "metadata": {},
   "source": [
    "#### Validate Model\n",
    "\n",
    "The model needs to get validated for Operator Coverage. Here the ONNX model is scanned and you get an output that shows a list of supported and unsupported operations by the compiler.\n",
    "\n",
    "The ONNX file path that is being validated is: `compiled_tiny_bert/model.onnx`\n",
    "\n",
    "The ``idiom.cc.onnx.check_op_cov`` API command invokes the Operator Coverage functionality. Here, it accepts two arguments: an ONNX model, and a .json file that defines the ONNX inputs.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "82695f6d-35c9-424f-865d-9c12afd59ab0",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2022-08-19 13:40:30,815 - check-op-cov - INFO - check-op-cov v0.5.0\n",
      "Date and time: August 19, 2022 13:40:30\n",
      "Source model path: /idiom-eap/examples/00-getting-started/tutorials/bert-tiny/perf/compiled_tiny_bert/model.onnx\n",
      "2022-08-19 13:40:30,816 - check-op-cov - INFO - Output files will be saved in /idiom-eap/examples/00-getting-started/tutorials/bert-tiny/perf/compiled_tiny_bert/model_opcov\n",
      "2022-08-19 13:40:30,817 - check-op-cov - INFO - Running operator coverage tool...\n",
      "2022-08-19 13:40:30,961 - check-op-cov - INFO - Finished running operator coverage tool.\n",
      "2022-08-19 13:40:30,971 - check-op-cov - INFO - General messages from the compiler:\n",
      "ONNX opset version 12\n",
      "Setting parameter 'batch' to 1 from input declaration.\n",
      "Setting parameter 'sequence' to 384 from input declaration.\n",
      "ONNX IR version 7\n",
      "ONNX producer \"pytorch\" version 1.10\n",
      "ONNX model version 0\n",
      "\n",
      "2022-08-19 13:40:30,971 - check-op-cov - INFO - 224/224 operators from 21 op types passed. All ops are supported!\n",
      "2022-08-19 13:40:30,973 - check-op-cov - INFO - Op types summary:\n",
      "Op Type     Total          Supported      Unsupported    Failed         \n",
      "------------------------------------------------------------------------\n",
      "Add         34             34             0              0              \n",
      "Cast        1              1              0              0              \n",
      "Concat      8              8              0              0              \n",
      "Constant    39             39             0              0              \n",
      "Div         9              9              0              0              \n",
      "Erf         2              2              0              0              \n",
      "Gather      20             20             0              0              \n",
      "MatMul      17             17             0              0              \n",
      "Mul         10             10             0              0              \n",
      "Pow         5              5              0              0              \n",
      "ReduceMean  10             10             0              0              \n",
      "Reshape     8              8              0              0              \n",
      "Shape       17             17             0              0              \n",
      "Slice       1              1              0              0              \n",
      "Softmax     2              2              0              0              \n",
      "Split       1              1              0              0              \n",
      "Sqrt        5              5              0              0              \n",
      "Squeeze     2              2              0              0              \n",
      "Sub         6              6              0              0              \n",
      "Transpose   8              8              0              0              \n",
      "Unsqueeze   19             19             0              0              \n",
      "\n",
      "2022-08-19 13:40:30,974 - check-op-cov - INFO - Visuals not created because all ops are supported.\n"
     ]
    }
   ],
   "source": [
    "from idiom.cc.onnx import check_op_cov\n",
    "check_op_cov('compiled_tiny_bert/model.onnx', onnx_define_inputs=\"bert-inputs.json\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fb534297-1425-4a8a-bd22-e47dc5f1cdd9",
   "metadata": {},
   "source": [
    "#### Compile\n",
    "\n",
    "The ``idiom.cc.onnx.compile`` API command invokes the Idiom Compiler, where an ONNX model is compiled for Envise. It accepts mainly three arguments:\n",
    "\n",
    "* **output_directory** \n",
    "\n",
    "    Directory where the output files will get stored after compilation.\n",
    "\n",
    "* **onnx_file_path**\n",
    "    \n",
    "    Path to the ONNX model.\n",
    "* **batch_size**\n",
    "\n",
    "    Number of samples within a batch used for ONNX export."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "17926dd4-cf13-4803-a8f6-9a5492bca0a5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Starting compiling...\n",
      "Done compiling\n"
     ]
    }
   ],
   "source": [
    "compile_flags = [\n",
    "    f'--onnx-declare-input=input_ids[{batch_size},{sequence_length}]'\n",
    "]\n",
    "\n",
    "from idiom.cc.onnx import compile\n",
    "print('Starting compiling...')\n",
    "idiom.cc.onnx.compile(compile_dir, onnx_file, batch_size, compile_flags)\n",
    "print('Done compiling')\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "17071c66-bb37-4f4a-939f-55cbb74e6531",
   "metadata": {},
   "source": [
    "#### Profile Model\n",
    "\n",
    "The ``idiom.runtime.profile`` API command invokes the profiler. It measures the model’s performance metrics such as Inferences Per Second (IPS) and latency of your model for Envise by profiling the execution of the model at runtime. \n",
    "\n",
    "It accepts two arguments:\n",
    "\n",
    "* **Compiled Model Directory**\n",
    "\n",
    "    The Compiled Model Directory where the compilation output resides.\n",
    "\n",
    "* **Input data**\n",
    "\n",
    "    A sequence of dictionaries containing model inputs. \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "8fa26fce-3189-4b5a-bcb2-538cdf29a855",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Profiling inferencing...\n",
      "Profiling compiled_tiny_bert\n",
      "    Loading model\n",
      "    Profiling model execution\n",
      "        Running batch 1 of 1\n",
      "\n",
      "Performance Report\n",
      "\n",
      "Source model path: compiled_tiny_bert\n",
      "Batch size: 2\n",
      "Number of Envises: 0.5\n",
      "\n",
      "+------------------------------------+-------------------------+----------------------+\n",
      "|         Measurement Scope          |   Inferences per Second |   Batch Latency (ms) |\n",
      "+====================================+=========================+======================+\n",
      "|  System Performance (CPU Compute,  |                      75 |                26.5  |\n",
      "| Envise Compute, and Data Transfer) |                         |                      |\n",
      "+------------------------------------+-------------------------+----------------------+\n",
      "|  Envise Compute and Data Transfer  |                    5136 |                 0.39 |\n",
      "+------------------------------------+-------------------------+----------------------+\n",
      "|        Only Envise Compute         |                    7543 |                 0.27 |\n",
      "+------------------------------------+-------------------------+----------------------+\n",
      "|          Only CPU Compute          |                      77 |                26.11 |\n",
      "+------------------------------------+-------------------------+----------------------+\n"
     ]
    }
   ],
   "source": [
    "import idiom.runtime\n",
    "print('Profiling inferencing...')\n",
    "idiom.runtime.profile(compile_dir, batches, detailed_report=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9a1a7484-6e31-40ac-8277-80391c72911d",
   "metadata": {},
   "source": [
    "#### Conclusion\n",
    "\n",
    "This tutorial shows how to validate, compile, and profile a ``Bert-Tiny`` model, and measure its performance metrics for Envise-behavior."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
