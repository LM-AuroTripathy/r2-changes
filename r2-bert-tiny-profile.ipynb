{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "2a1162ad",
   "metadata": {
    "tags": []
   },
   "source": [
    "## NOTEBOOK: Profile a BERT-Tiny Model\n",
    "\n",
    "This tutorial validates, compiles, and profiles a Bert-Tiny model for inference on Envise using the Idiom Software Stack.\n",
    "\n",
    "The model we're going to be working with is, [mrm8488/bert-tiny-finetuned-squadv2](https://huggingface.co/mrm8488/bert-tiny-finetuned-squadv2). You can find more about this model on Hugging Face.\n",
    "\n",
    "Run this Jupyter notebook on an environment that has a GPU instance. \n",
    "\n",
    "The model will traverse through the following stages in the developer flow:\n",
    "\n",
    "**Export model to ONNX**\n",
    "    \n",
    "    The original model is exported to ONNX before validating operator coverage. \n",
    "\n",
    "**Validate the model**\n",
    "    \n",
    "    The operator coverage tool is invoked at this stage and checks for supported and unsupported ONXX operators in the model. \n",
    "\n",
    "**Compile the model** \n",
    "    \n",
    "    The compile() Idiom API is invoked at this stage and the ONNX model is compiled for Envise.\n",
    "\n",
    "**Profile the model** \n",
    "    \n",
    "    The profile() Idiom API is invoked at this stage and the model is executed at runtime in an Envise-simulated environment for performance metrics.\n",
    "\n",
    "**SYSTEM COMPONENT MINIMUM REQUIREMENTS**\n",
    "\n",
    "* CPU: Any X86-64 architecture with 4 cores\n",
    "* RAM: 64 GB memory\n",
    "* GPU: One Nvidia 2080"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f6d3954e-1478-4464-b71e-650fbd744718",
   "metadata": {},
   "source": [
    "#### Install Dependencies\n",
    "This step takes under one minute"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5a197f48-4541-4f8a-80db-e699fbf0c0ad",
   "metadata": {},
   "outputs": [],
   "source": [
    "!pip install -r requirements.txt"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9d3a96e5-fbb1-4265-a8c2-3ec94dda953e",
   "metadata": {},
   "source": [
    "#### Set up Imports "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2e7b8f07",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Standard imports\n",
    "import os\n",
    "import sys\n",
    "import argparse\n",
    "\n",
    "import numpy as np\n",
    "from pathlib import Path\n",
    "from typing import Mapping\n",
    "from collections import OrderedDict\n",
    "\n",
    "# HuggingFace imports\n",
    "import datasets\n",
    "from transformers.onnx.convert import export\n",
    "from transformers.onnx.config import OnnxConfig\n",
    "from transformers import BertForQuestionAnswering, BertTokenizer\n",
    "\n",
    "# Lightmatter imports\n",
    "import idiom"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ebf75e42-de47-4a53-8c8b-2a856d076016",
   "metadata": {},
   "source": [
    "#### Define Inputs and Outputs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8b7f2d91",
   "metadata": {},
   "outputs": [],
   "source": [
    "# OnnxConfig is an abstract class, so we need a concrete base class that\n",
    "# provides a name for each tensor & their dimensions. These names are\n",
    "# emitted into the ONNX file.\n",
    "class BertOnnxConfig(OnnxConfig):\n",
    "    def __init__(self, config, task):\n",
    "        super().__init__(config,task)\n",
    "\n",
    "    @property\n",
    "    def inputs(self) -> Mapping[str, Mapping[int, str]]:\n",
    "        return OrderedDict(\n",
    "            {\n",
    "                \"input_ids\":      {0: \"batch\", 1: \"sequence\"},\n",
    "                \"attention_mask\": {0: \"batch\", 1: \"sequence\"},\n",
    "                \"token_type_ids\": {0: \"batch\", 1: \"sequence\"}\n",
    "            }\n",
    "        )\n",
    "\n",
    "    @property\n",
    "    def outputs(self) -> Mapping[str, Mapping[int, str]]:\n",
    "        return OrderedDict(\n",
    "            {\n",
    "                \"start_logits\": {0: \"batch\", 1: \"sequence\"},\n",
    "                \"end_logits\":   {0: \"batch\", 1: \"sequence\"}\n",
    "            }\n",
    "        )"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "18aaa63d-9414-4f4b-b152-c7d1cfaba7fa",
   "metadata": {},
   "source": [
    "#### Define a Function to Encode Inputs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "291a26c8-ea3d-4062-accb-28ea4da21036",
   "metadata": {},
   "outputs": [],
   "source": [
    "def encode_batch(tokenizer, questions, contexts, seq_len):\n",
    "    '''\n",
    "    Calls tokenizer.encode_plus() for each given question+context pair. All\n",
    "    samples are encoded to length <seq_len>; shorter inputs are zero-padded\n",
    "    and longer inputs are truncated.\n",
    "\n",
    "    Params:\n",
    "        tokenizer:             Tokenizer to use for encoding\n",
    "        questions (list[str]): Set of questions\n",
    "        contexts  (list[str]): Set of contexts (length must match questions)\n",
    "        seq_len (int):         Fixed length of encoded samples\n",
    "\n",
    "    Returns: Dictionary of [batch_size x seq_len] tensors (np.array) for\n",
    "        token IDs, segment IDs, and attention masks.\n",
    "    '''\n",
    "\n",
    "    input_ids = []\n",
    "    tkn_types = []\n",
    "    attn_mask = []\n",
    "\n",
    "    for q,c in zip(questions,contexts):\n",
    "        inputs = tokenizer.encode_plus(q,c,return_tensors='np',truncation=True,padding='max_length',max_length=seq_len)\n",
    "        input_ids.append(inputs['input_ids'])\n",
    "        tkn_types.append(inputs['token_type_ids'])\n",
    "        attn_mask.append(inputs['attention_mask'])\n",
    "\n",
    "    input_ids = np.vstack(input_ids)\n",
    "    tkn_types = np.vstack(tkn_types)\n",
    "    attn_mask = np.vstack(attn_mask)\n",
    "\n",
    "    return {\n",
    "        'input_ids' : input_ids,\n",
    "        'token_type_ids' : tkn_types,\n",
    "        'attention_mask' : attn_mask\n",
    "    }\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a5d8c89c-86ef-4f19-b8e2-a729b754b492",
   "metadata": {},
   "source": [
    "#### Initialize the Profiling Parameters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "94cdbfa7-9334-4e32-88d1-9025fe0fdca4",
   "metadata": {},
   "outputs": [],
   "source": [
    "num_batches = 1\n",
    "batch_size = 2\n",
    "sequence_length = 384"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a47d8238-e509-4173-b362-28e901664436",
   "metadata": {},
   "source": [
    "#### Download Model Parameters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b0c5b727-a0aa-49f3-bfde-506052b20efe",
   "metadata": {},
   "outputs": [],
   "source": [
    "compile_dir = f'compiled_tiny_bert'\n",
    "onnx_file = compile_dir + '/model.onnx'\n",
    "\n",
    "os.makedirs(compile_dir,exist_ok=True)\n",
    "\n",
    "\n",
    "hf_model_name = 'mrm8488/bert-tiny-finetuned-squadv2'\n",
    "\n",
    "print('Downloading model parameters...')\n",
    "model     = BertForQuestionAnswering.from_pretrained(hf_model_name).eval()\n",
    "tokenizer = BertTokenizer.from_pretrained(hf_model_name)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b2713296-94c3-46d9-a682-1dec525ff679",
   "metadata": {},
   "source": [
    "#### Get Dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0e574ddc-97fa-423d-a767-585090fe0974",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Download dataset from HuggingFace hub\n",
    "print('Downloading SQUADv2 dataset...')\n",
    "squad = datasets.load_dataset('squad_v2', split='validation')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "02f734af-7624-4113-9924-806cbdd3d3ba",
   "metadata": {},
   "source": [
    "#### Encode Inputs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1ce4a54f-111b-4db2-8098-80c1b2d4f87b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Encode plain-text paragraphs & questions into token IDs, segment IDs, and attention masks\n",
    "batches = []\n",
    "print('Encoding inputs...')\n",
    "\n",
    "for i in range(num_batches):\n",
    "    batch = list(squad)[i*batch_size:(i+1)*batch_size]\n",
    "    questions = [q['question'] for q in batch]\n",
    "    contexts  = [q['context']  for q in batch]\n",
    "    encoded_inputs = encode_batch(tokenizer,questions,contexts,sequence_length)\n",
    "    batches.append(encoded_inputs)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1e1bf646-0f16-4ce8-9048-9ef5b84c52d7",
   "metadata": {},
   "source": [
    "#### Export the Model to ONNX"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "50b48414-e004-44ee-9a85-ad7ced37ad2a",
   "metadata": {},
   "outputs": [],
   "source": [
    "print('Exporting model to ONNX...')\n",
    "config = BertOnnxConfig(model.config, task='question-answering')\n",
    "export(tokenizer,model,config,opset=12,output=Path(onnx_file))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "60f1bfa2-158f-4f27-a256-38280e32bb21",
   "metadata": {},
   "source": [
    "#### Validate Model\n",
    "\n",
    "The model needs to get validated for Operator Coverage. Here the ONNX model is scanned and you get an output that shows a list of supported and unsupported operations by the compiler.\n",
    "\n",
    "The ONNX file path that is being validated is: `compiled_tiny_bert/model.onnx`\n",
    "\n",
    "The ``idiom.cc.onnx.check_op_cov`` API command invokes the Operator Coverage functionality. Here, it accepts two arguments: an ONNX model, and a .json file that defines the ONNX inputs.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "82695f6d-35c9-424f-865d-9c12afd59ab0",
   "metadata": {},
   "outputs": [],
   "source": [
    "from idiom.cc.onnx import check_op_cov\n",
    "check_op_cov('compiled_tiny_bert/model.onnx', onnx_define_inputs=\"bert-inputs.json\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fb534297-1425-4a8a-bd22-e47dc5f1cdd9",
   "metadata": {},
   "source": [
    "#### Compile\n",
    "\n",
    "The ``idiom.cc.onnx.compile`` API command invokes the Idiom Compiler, where an ONNX model is compiled for Envise. It accepts mainly three arguments:\n",
    "\n",
    "* **output_directory** \n",
    "\n",
    "    Directory where the output files will get stored after compilation.\n",
    "\n",
    "* **onnx_file_path**\n",
    "    \n",
    "    Path to the ONNX model.\n",
    "* **batch_size**\n",
    "\n",
    "    Number of samples within a batch used for ONNX export."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "17926dd4-cf13-4803-a8f6-9a5492bca0a5",
   "metadata": {},
   "outputs": [],
   "source": [
    "compile_flags = [\n",
    "    f'--onnx-declare-input=input_ids[{batch_size},{sequence_length}]'\n",
    "]\n",
    "\n",
    "from idiom.cc.onnx import compile\n",
    "print('Starting compiling...')\n",
    "idiom.cc.onnx.compile(compile_dir, onnx_file, batch_size, compile_flags)\n",
    "print('Done compiling')\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "17071c66-bb37-4f4a-939f-55cbb74e6531",
   "metadata": {},
   "source": [
    "#### Profile Model\n",
    "\n",
    "The ``idiom.runtime.profile`` API command invokes the profiler. It measures the modelâ€™s performance metrics such as Inferences Per Second (IPS) and latency of your model for Envise by profiling the execution of the model at runtime. \n",
    "\n",
    "It accepts two arguments:\n",
    "\n",
    "* **Compiled Model Directory**\n",
    "\n",
    "    The Compiled Model Directory where the compilation output resides.\n",
    "\n",
    "* **Input data**\n",
    "\n",
    "    A sequence of dictionaries containing model inputs. \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8fa26fce-3189-4b5a-bcb2-538cdf29a855",
   "metadata": {},
   "outputs": [],
   "source": [
    "import idiom.runtime\n",
    "print('Profiling inferencing...')\n",
    "idiom.runtime.profile(compile_dir, batches, detailed_report=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9a1a7484-6e31-40ac-8277-80391c72911d",
   "metadata": {},
   "source": [
    "#### Conclusion\n",
    "\n",
    "This tutorial shows how to validate, compile, and profile a ``Bert-Tiny`` model, and measure its performance metrics for Envise-behavior."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
