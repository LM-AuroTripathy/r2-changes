{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "2a1162ad",
   "metadata": {
    "tags": []
   },
   "source": [
    "## NOTEBOOK: Profile a BERT-Tiny Model\n",
    "\n",
    "This tutorial validates, compiles, and profiles a Bert-Tiny model for inference on Envise using the Idiom Software Stack.\n",
    "\n",
    "The model we're going to be working with is, [mrm8488/bert-tiny-finetuned-squadv2](https://huggingface.co/mrm8488/bert-tiny-finetuned-squadv2). You can find more about this model on Hugging Face.\n",
    "\n",
    "Run this Jupyter notebook on an environment that has a GPU instance. \n",
    "\n",
    "The model will traverse through the following stages in the developer flow:\n",
    "\n",
    "**Export model to ONNX**\n",
    "    \n",
    "    The original model is exported to ONNX before validating operator coverage. \n",
    "\n",
    "**Validate the model**\n",
    "    \n",
    "    The operator coverage tool is invoked at this stage and checks for supported and unsupported ONXX operators in the model. \n",
    "\n",
    "**Compile the model** \n",
    "    \n",
    "    The compile() Idiom API is invoked at this stage and the ONNX model is compiled for Envise.\n",
    "\n",
    "**Profile the model** \n",
    "    \n",
    "    The profile() Idiom API is invoked at this stage and the model is executed at runtime in an Envise-simulated environment for performance metrics.\n",
    "\n",
    "**SYSTEM COMPONENT MINIMUM REQUIREMENTS**\n",
    "\n",
    "* CPU: Any X86-64 architecture with 4 cores\n",
    "* RAM: 64 GB memory\n",
    "* GPU: One Nvidia 2080"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f6d3954e-1478-4464-b71e-650fbd744718",
   "metadata": {},
   "source": [
    "#### Install Dependencies\n",
    "This step takes under one minute"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5a197f48-4541-4f8a-80db-e699fbf0c0ad",
   "metadata": {},
   "outputs": [],
   "source": [
    "!pip install -r requirements.txt"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9d3a96e5-fbb1-4265-a8c2-3ec94dda953e",
   "metadata": {},
   "source": [
    "#### Set up Imports "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2e7b8f07",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Standard imports\n",
    "import os\n",
    "import sys\n",
    "import argparse\n",
    "\n",
    "import numpy as np\n",
    "from pathlib import Path\n",
    "from typing import Mapping\n",
    "from collections import OrderedDict\n",
    "\n",
    "# HuggingFace imports\n",
    "import datasets\n",
    "from transformers.onnx.convert import export\n",
    "from transformers.onnx.config import OnnxConfig\n",
    "from transformers import BertForQuestionAnswering, BertTokenizer\n",
    "\n",
    "# Lightmatter imports\n",
    "import idiom"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ebf75e42-de47-4a53-8c8b-2a856d076016",
   "metadata": {},
   "source": [
    "#### Define Inputs and Outputs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8b7f2d91",
   "metadata": {},
   "outputs": [],
   "source": [
    "# OnnxConfig is an abstract class, so we need a concrete base class that\n",
    "# provides a name for each tensor & their dimensions. These names are\n",
    "# emitted into the ONNX file.\n",
    "class BertOnnxConfig(OnnxConfig):\n",
    "    def __init__(self, config, task):\n",
    "        super().__init__(config,task)\n",
    "\n",
    "    @property\n",
    "    def inputs(self) -> Mapping[str, Mapping[int, str]]:\n",
    "        return OrderedDict(\n",
    "            {\n",
    "                \"input_ids\":      {0: \"batch\", 1: \"sequence\"},\n",
    "                \"attention_mask\": {0: \"batch\", 1: \"sequence\"},\n",
    "                \"token_type_ids\": {0: \"batch\", 1: \"sequence\"}\n",
    "            }\n",
    "        )\n",
    "\n",
    "    @property\n",
    "    def outputs(self) -> Mapping[str, Mapping[int, str]]:\n",
    "        return OrderedDict(\n",
    "            {\n",
    "                \"start_logits\": {0: \"batch\", 1: \"sequence\"},\n",
    "                \"end_logits\":   {0: \"batch\", 1: \"sequence\"}\n",
    "            }\n",
    "        )"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "18aaa63d-9414-4f4b-b152-c7d1cfaba7fa",
   "metadata": {},
   "source": [
    "#### Define a Function to Encode Inputs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "291a26c8-ea3d-4062-accb-28ea4da21036",
   "metadata": {},
   "outputs": [],
   "source": [
    "def encode_batch(tokenizer, questions, contexts, seq_len):\n",
    "    '''\n",
    "    Calls tokenizer.encode_plus() for each given question+context pair. All\n",
    "    samples are encoded to length <seq_len>; shorter inputs are zero-padded\n",
    "    and longer inputs are truncated.\n",
    "\n",
    "    Params:\n",
    "        tokenizer:             Tokenizer to use for encoding\n",
    "        questions (list[str]): Set of questions\n",
    "        contexts  (list[str]): Set of contexts (length must match questions)\n",
    "        seq_len (int):         Fixed length of encoded samples\n",
    "\n",
    "    Returns: Dictionary of [batch_size x seq_len] tensors (np.array) for\n",
    "        token IDs, segment IDs, and attention masks.\n",
    "    '''\n",
    "\n",
    "    input_ids = []\n",
    "    tkn_types = []\n",
    "    attn_mask = []\n",
    "\n",
    "    for q,c in zip(questions,contexts):\n",
    "        inputs = tokenizer.encode_plus(q,c,return_tensors='np',truncation=True,padding='max_length',max_length=seq_len)\n",
    "        input_ids.append(inputs['input_ids'])\n",
    "        tkn_types.append(inputs['token_type_ids'])\n",
    "        attn_mask.append(inputs['attention_mask'])\n",
    "\n",
    "    input_ids = np.vstack(input_ids)\n",
    "    tkn_types = np.vstack(tkn_types)\n",
    "    attn_mask = np.vstack(attn_mask)\n",
    "\n",
    "    return {\n",
    "        'input_ids' : input_ids,\n",
    "        'token_type_ids' : tkn_types,\n",
    "        'attention_mask' : attn_mask\n",
    "    }\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a5d8c89c-86ef-4f19-b8e2-a729b754b492",
   "metadata": {},
   "source": [
    "#### Initialize the Profiling Parameters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "94cdbfa7-9334-4e32-88d1-9025fe0fdca4",
   "metadata": {},
   "outputs": [],
   "source": [
    "num_batches = 1\n",
    "batch_size = 2\n",
    "sequence_length = 384"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a47d8238-e509-4173-b362-28e901664436",
   "metadata": {},
   "source": [
    "#### Download Model Parameters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b0c5b727-a0aa-49f3-bfde-506052b20efe",
   "metadata": {},
   "outputs": [],
   "source": [
    "compile_dir = f'compiled_tiny_bert'\n",
    "onnx_file = compile_dir + '/model.onnx'\n",
    "\n",
    "os.makedirs(compile_dir,exist_ok=True)\n",
    "\n",
    "\n",
    "hf_model_name = 'mrm8488/bert-tiny-finetuned-squadv2'\n",
    "\n",
    "print('Downloading model parameters...')\n",
    "model     = BertForQuestionAnswering.from_pretrained(hf_model_name).eval()\n",
    "tokenizer = BertTokenizer.from_pretrained(hf_model_name)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b2713296-94c3-46d9-a682-1dec525ff679",
   "metadata": {},
   "source": [
    "#### Get Dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0e574ddc-97fa-423d-a767-585090fe0974",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Download dataset from HuggingFace hub\n",
    "print('Downloading SQUADv2 dataset...')\n",
    "squad = datasets.load_dataset('squad_v2', split='validation')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "02f734af-7624-4113-9924-806cbdd3d3ba",
   "metadata": {},
   "source": [
    "#### Encode Inputs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1ce4a54f-111b-4db2-8098-80c1b2d4f87b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Encode plain-text paragraphs & questions into token IDs, segment IDs, and attention masks\n",
    "batches = []\n",
    "print('Encoding inputs...')\n",
    "\n",
    "for i in range(num_batches):\n",
    "    batch = list(squad)[i*batch_size:(i+1)*batch_size]\n",
    "    questions = [q['question'] for q in batch]\n",
    "    contexts  = [q['context']  for q in batch]\n",
    "    encoded_inputs = encode_batch(tokenizer,questions,contexts,sequence_length)\n",
    "    batches.append(encoded_inputs)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1e1bf646-0f16-4ce8-9048-9ef5b84c52d7",
   "metadata": {},
   "source": [
    "#### Export the Model to ONNX"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "50b48414-e004-44ee-9a85-ad7ced37ad2a",
   "metadata": {},
   "outputs": [],
   "source": [
    "print('Exporting model to ONNX...')\n",
    "config = BertOnnxConfig(model.config, task='question-answering')\n",
    "export(tokenizer,model,config,opset=12,output=Path(onnx_file))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "60f1bfa2-158f-4f27-a256-38280e32bb21",
   "metadata": {},
   "source": [
    "#### Validate Model\n",
    "\n",
    "The model needs to get validated for Operator Coverage. Here the ONNX model is scanned and you get an output that shows a list of supported and unsupported operations by the compiler.\n",
    "\n",
    "The ONNX file path that is being validated is: `compiled_tiny_bert/model.onnx`\n",
    "\n",
    "The ``idiom.cc.onnx.check_op_cov`` API command invokes the Operator Coverage functionality. Here, it accepts two arguments: an ONNX model, and a .json file that defines the ONNX inputs.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "82695f6d-35c9-424f-865d-9c12afd59ab0",
   "metadata": {},
   "outputs": [],
   "source": [
    "from idiom.cc.onnx import check_op_cov\n",
    "check_op_cov('compiled_tiny_bert/model.onnx', onnx_define_inputs=\"bert-inputs.json\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fb534297-1425-4a8a-bd22-e47dc5f1cdd9",
   "metadata": {},
   "source": [
    "#### Compile\n",
    "\n",
    "The ``idiom.cc.onnx.compile`` API command invokes the Idiom Compiler, where an ONNX model is compiled for Envise. It accepts mainly three arguments:\n",
    "\n",
    "* **output_directory** \n",
    "\n",
    "    Directory where the output files will get stored after compilation.\n",
    "\n",
    "* **onnx_file_path**\n",
    "    \n",
    "    Path to the ONNX model.\n",
    "* **batch_size**\n",
    "\n",
    "    Number of samples within a batch used for ONNX export."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "17926dd4-cf13-4803-a8f6-9a5492bca0a5",
   "metadata": {},
   "outputs": [],
   "source": [
    "compile_flags = [\n",
    "    f'--onnx-declare-input=input_ids[{batch_size},{sequence_length}]'\n",
    "]\n",
    "\n",
    "from idiom.cc.onnx import compile\n",
    "print('Starting compiling...')\n",
    "idiom.cc.onnx.compile(compile_dir, onnx_file, batch_size, compile_flags)\n",
    "print('Done compiling')\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "17071c66-bb37-4f4a-939f-55cbb74e6531",
   "metadata": {},
   "source": [
    "#### Profile Model\n",
    "\n",
    "The ``idiom.runtime.profile`` API command invokes the profiler. It measures the model’s performance metrics such as Inferences Per Second (IPS) and latency of your model for Envise by profiling the execution of the model at runtime. \n",
    "\n",
    "It accepts two arguments:\n",
    "\n",
    "* **Compiled Model Directory**\n",
    "\n",
    "    The Compiled Model Directory where the compilation output resides.\n",
    "\n",
    "* **Input data**\n",
    "\n",
    "    A sequence of dictionaries containing model inputs. \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8fa26fce-3189-4b5a-bcb2-538cdf29a855",
   "metadata": {},
   "outputs": [],
   "source": [
    "import idiom.runtime\n",
    "print('Profiling inferencing...')\n",
    "idiom.runtime.profile(compile_dir, batches, detailed_report=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9a1a7484-6e31-40ac-8277-80391c72911d",
   "metadata": {},
   "source": [
    "#### Conclusion\n",
    "\n",
    "This tutorial shows how to validate, compile, and profile a ``Bert-Tiny`` model, and measure its performance metrics for Envise-behavior."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
