{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "2a1162ad",
   "metadata": {},
   "source": [
    "## NOTEBOOK: Profile a ResNet18 Model\n",
    "\n",
    "This tutorial validates, compiles, and profiles a ResNet18 model for inference on Envise using the Idiom Software Stack.\n",
    "\n",
    "Run this Jupyter notebook on an environment that has a GPU instance. \n",
    "\n",
    "The model will traverse through the following stages in the developer flow:\n",
    "\n",
    "**Validate the model**\n",
    "    \n",
    "    The operator coverage tool is invoked at this stage and checks for supported and unsupported ONXX operators in the model. \n",
    "\n",
    "**Compile the model** \n",
    "    \n",
    "    The compile() Idiom API is invoked at this stage and the ONNX model is compiled for Envise.\n",
    "\n",
    "**Profile the model** \n",
    "    \n",
    "    The profile() Idiom API is invoked at this stage and the model is executed at runtime in an Envise-simulated environment for performance metrics.\n",
    "\n",
    "**SYSTEM COMPONENT MINIMUM REQUIREMENTS**\n",
    "\n",
    "* CPU: Any X86-64 architecture with 4 cores\n",
    "* RAM: 64 GB memory\n",
    "* GPU: One Nvidia 2080"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ecc5f8f5",
   "metadata": {},
   "source": [
    "#### Set up Imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2e7b8f07",
   "metadata": {},
   "outputs": [],
   "source": [
    "import idiom\n",
    "import torch\n",
    "import torchvision\n",
    "import torchvision.datasets as datasets\n",
    "import torchvision.transforms as transforms\n",
    "import itertools"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8888b22a-b893-4192-b821-7643769dd74d",
   "metadata": {},
   "source": [
    "#### Export file to ONNX\n",
    "Specify the `batch_size` and use the variable where ever the batch size is required."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bac73ded-6062-4906-b360-2e221f752712",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torchvision.models as models\n",
    "model = models.resnet18(pretrained=False, num_classes=10)\n",
    "model.load_state_dict(torch.load('/idiom-eap/examples/00-getting-started/resnet-18-imagewoof2-320.pth'))\n",
    "model.eval()\n",
    "onnx_file_name = 'rn18.onnx'\n",
    "batch_size  = 2\n",
    "# Input to the model with the batch_size\n",
    "x = torch.randn(batch_size, 3, 320, 320, requires_grad=True)\n",
    "\n",
    "torch.onnx.export(model,                  # model being run\n",
    "                  x,                      # model input (or a tuple for multiple inputs)\n",
    "                  onnx_file_name,         # where to save the model (can be a file or file-like object)\n",
    "                  verbose=False,\n",
    "                  input_names = ['input'],   # the model's input names\n",
    "                  output_names = ['output'],) # the model's output names\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "06147ffe-7300-4e88-99ee-e6bd5194e393",
   "metadata": {},
   "source": [
    "#### Validate Model\n",
    "\n",
    "The model needs to get validated for Operator Coverage. Here the ONNX model is scanned and you get an output that shows a list of supported and unsupported operations by the compiler.\n",
    "\n",
    "The ONNX file that is being validated is: `resnet-18-imagewoof2-320.onnx`\n",
    "\n",
    "The ``idiom.cc.onnx.check_op_cov`` API command invokes the Operator Coverage functionality. It accepts one argument: an ONNX model.\n",
    " "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f1080fc6-766a-4870-ab67-2f74defb8800",
   "metadata": {},
   "outputs": [],
   "source": [
    "from idiom.cc.onnx import check_op_cov\n",
    "check_op_cov(onnx_file_name)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3cb42e2c-0083-42c8-ac53-89c1c1c8758d",
   "metadata": {},
   "source": [
    "Above, you can see that the model is fully supported. Thus, it is suitable for compilation. "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bf7e9408-6e6b-43b2-8a62-586f794da781",
   "metadata": {},
   "source": [
    "#### Compile\n",
    "\n",
    "The ``idiom.cc.onnx.compile`` API command invokes the Idiom Compiler, where an ONNX model is compiled for Envise. It accepts mainly three arguments:\n",
    "\n",
    "* **output_directory** \n",
    "\n",
    "    Directory where the output files will get stored after compilation.\n",
    "\n",
    "* **onnx_file_path**\n",
    "    \n",
    "    Path to the ONNX model.\n",
    "* **batch_size**\n",
    "    \n",
    "    Number of samples within a batch used for ONNX export."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8b7f2d91",
   "metadata": {},
   "outputs": [],
   "source": [
    "from idiom.cc.onnx import compile\n",
    "compiled_model_path = 'compiled-onnx'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f75e8422",
   "metadata": {},
   "outputs": [],
   "source": [
    "print('Starting compiling...')\n",
    "idiom.cc.onnx.compile(compiled_model_path, onnx_file_name, batch_size=batch_size)\n",
    "print('Done compiling')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a5d8c89c-86ef-4f19-b8e2-a729b754b492",
   "metadata": {},
   "source": [
    "#### Get Dataset\n",
    "\n",
    "Get the ImageWoof dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "657b17b7-832f-44b3-8c68-2f2920715270",
   "metadata": {},
   "outputs": [],
   "source": [
    "!wget https://s3.amazonaws.com/fast-ai-imageclas/imagewoof2-320.tgz"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a45218f9-970f-400b-ae46-b6a3b949a713",
   "metadata": {},
   "outputs": [],
   "source": [
    "!tar xf imagewoof2-320.tgz  # silent\n",
    "!echo \"Done\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1ce4a54f-111b-4db2-8098-80c1b2d4f87b",
   "metadata": {},
   "outputs": [],
   "source": [
    "!ls -l imagewoof2-320  # check you have the train and validation folders"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1e1bf646-0f16-4ce8-9048-9ef5b84c52d7",
   "metadata": {},
   "source": [
    "#### Load Dataset\n",
    "\n",
    "Load the dataset and initialize the Dataloader features."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "50b48414-e004-44ee-9a85-ad7ced37ad2a",
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_input_data(dataset_path: str):\n",
    "    print('Loading input data')\n",
    "\n",
    "    loader = torch.utils.data.DataLoader(\n",
    "        datasets.ImageFolder(dataset_path, \n",
    "                             transforms.Compose([\n",
    "                                 transforms.Resize((320, 320)),\n",
    "                                 transforms.ToTensor(),\n",
    "                                 transforms.Normalize(mean=[0.485, 0.456, 0.406], std=[0.229, 0.224, 0.225])])),\n",
    "        batch_size=batch_size, \n",
    "        shuffle=False,\n",
    "        num_workers=1, \n",
    "        pin_memory=False)\n",
    "\n",
    "    data = [{'input': x[0].numpy()} for x in itertools.islice(loader, 1)]\n",
    "\n",
    "    return data"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fb534297-1425-4a8a-bd22-e47dc5f1cdd9",
   "metadata": {},
   "source": [
    "\n",
    "#### Profile Model\n",
    "\n",
    "The ``idiom.runtime.profile`` API command invokes the profiler. It measures the modelâ€™s performance metrics such as Inferences Per Second (IPS) and latency of your model for Envise by profiling the execution of the model at runtime. \n",
    "\n",
    "It mainly accepts two arguments:\n",
    "\n",
    "* **Compiled Model Directory**\n",
    "\n",
    "    The Compiled Model Directory where the compilation output resides.\n",
    "\n",
    "* **Input data**\n",
    "\n",
    "    A sequence of dictionaries containing model inputs. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "17926dd4-cf13-4803-a8f6-9a5492bca0a5",
   "metadata": {},
   "outputs": [],
   "source": [
    "from idiom.runtime import profile\n",
    "dataset_path = 'imagewoof2-320'\n",
    "print('Starting loading & profiling...this may take a few seconds')\n",
    "input_data = load_input_data(dataset_path)\n",
    "compiled_model_dir = 'compiled-onnx'\n",
    "idiom.runtime.profile(compiled_model_dir, input_data, detailed_report=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "47d91cb3-362b-4380-821a-5ea65ad3858b",
   "metadata": {},
   "source": [
    "#### Conclusion\n",
    "\n",
    "This tutorial shows how to validate, compile, and profile a ``ResNet18`` model, and measure its performance metrics for Envise-behavior.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a6410c54-25ac-4a39-8386-8806f438edf0",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
