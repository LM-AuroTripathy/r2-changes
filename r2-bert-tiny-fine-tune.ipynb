{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## NOTEBOOK: Fine-tune a BERT-Tiny Model\n",
    "\n",
    "This notebook evaluates, simulates Envise-conditions, and fine-tunes a BERT-Tiny model for Envise-behavior using the Idiom Software Stack and the Accuracy Estimator tool. \n",
    "\n",
    "We are using the BERT \"Question-Answer\" model: [mrm8488/bert-tiny-finetuned-squadv2](https://huggingface.co/mrm8488/bert-tiny-finetuned-squadv2). It is relatively small and we can complete all the steps within 30 minutes. You can find the model details on Hugging Face.\n",
    "\n",
    "The dataset for this model is ``squadv2``.\n",
    "\n",
    "Run this Jupyter notebook on an environment that has a GPU instance.\n",
    "\n",
    "This notebook is in continuation to the `bert-tiny-profile.ipynb` notebook. To understand the full context, you run it before continuing with this notebook.\n",
    "\n",
    "**PROCESS**\n",
    "\n",
    "The following process describes the fine-tuning process used in this notebook:\n",
    "\n",
    "* First, evaluate the out-of-box accuracy of the FP32 BERT-Tiny model.\n",
    "\n",
    "* Next, estimate the model's accuracy in Envise precision by running the model using the Idiom API that calls the Envise Accuracy Estimator. Note that this is an estimate and most probably will be lower than the original FP32 accuracy.\n",
    "\n",
    "* Last, we apply the fine-tuning algorithm on the model by calling the Idiom API that returns a \"fine-tuned\" FP32 model with an improved accuracy score (closer to the original FP32 accuracy score). \n",
    "\n",
    "**SYSTEM COMPONENT MINIMUM REQUIREMENTS**\n",
    "\n",
    "* CPU: Any X86-64 architecture with 4 cores\n",
    "* RAM: 64 GB memory\n",
    "* GPU: One Nvidia 2080"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Install dependencies"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: psutil in /opt/venv/lib/python3.8/site-packages (from -r requirements.txt (line 1)) (5.9.1)\n",
      "Requirement already satisfied: accelerate==0.5.1 in /opt/venv/lib/python3.8/site-packages (from -r requirements.txt (line 2)) (0.5.1)\n",
      "Requirement already satisfied: datasets==1.18.3 in /opt/venv/lib/python3.8/site-packages (from -r requirements.txt (line 3)) (1.18.3)\n",
      "Requirement already satisfied: transformers[onnx]==4.16.2 in /opt/venv/lib/python3.8/site-packages (from -r requirements.txt (line 4)) (4.16.2)\n",
      "Requirement already satisfied: pyyaml in /opt/venv/lib/python3.8/site-packages (from accelerate==0.5.1->-r requirements.txt (line 2)) (6.0)\n",
      "Requirement already satisfied: numpy>=1.17 in /opt/venv/lib/python3.8/site-packages (from accelerate==0.5.1->-r requirements.txt (line 2)) (1.23.2)\n",
      "Requirement already satisfied: torch>=1.4.0 in /opt/venv/lib/python3.8/site-packages (from accelerate==0.5.1->-r requirements.txt (line 2)) (1.10.0+cu111)\n",
      "Requirement already satisfied: pyarrow!=4.0.0,>=3.0.0 in /opt/venv/lib/python3.8/site-packages (from datasets==1.18.3->-r requirements.txt (line 3)) (9.0.0)\n",
      "Requirement already satisfied: requests>=2.19.0 in /opt/venv/lib/python3.8/site-packages (from datasets==1.18.3->-r requirements.txt (line 3)) (2.28.1)\n",
      "Requirement already satisfied: multiprocess in /opt/venv/lib/python3.8/site-packages (from datasets==1.18.3->-r requirements.txt (line 3)) (0.70.13)\n",
      "Requirement already satisfied: tqdm>=4.62.1 in /opt/venv/lib/python3.8/site-packages (from datasets==1.18.3->-r requirements.txt (line 3)) (4.64.0)\n",
      "Requirement already satisfied: fsspec[http]>=2021.05.0 in /opt/venv/lib/python3.8/site-packages (from datasets==1.18.3->-r requirements.txt (line 3)) (2022.7.1)\n",
      "Requirement already satisfied: pandas in /opt/venv/lib/python3.8/site-packages (from datasets==1.18.3->-r requirements.txt (line 3)) (1.4.3)\n",
      "Requirement already satisfied: dill in /opt/venv/lib/python3.8/site-packages (from datasets==1.18.3->-r requirements.txt (line 3)) (0.3.5.1)\n",
      "Requirement already satisfied: xxhash in /opt/venv/lib/python3.8/site-packages (from datasets==1.18.3->-r requirements.txt (line 3)) (3.0.0)\n",
      "Requirement already satisfied: huggingface-hub<1.0.0,>=0.1.0 in /opt/venv/lib/python3.8/site-packages (from datasets==1.18.3->-r requirements.txt (line 3)) (0.8.1)\n",
      "Requirement already satisfied: aiohttp in /opt/venv/lib/python3.8/site-packages (from datasets==1.18.3->-r requirements.txt (line 3)) (3.8.1)\n",
      "Requirement already satisfied: packaging in /opt/venv/lib/python3.8/site-packages (from datasets==1.18.3->-r requirements.txt (line 3)) (21.3)\n",
      "Requirement already satisfied: regex!=2019.12.17 in /opt/venv/lib/python3.8/site-packages (from transformers[onnx]==4.16.2->-r requirements.txt (line 4)) (2022.7.25)\n",
      "Requirement already satisfied: sacremoses in /opt/venv/lib/python3.8/site-packages (from transformers[onnx]==4.16.2->-r requirements.txt (line 4)) (0.0.53)\n",
      "Requirement already satisfied: tokenizers!=0.11.3,>=0.10.1 in /opt/venv/lib/python3.8/site-packages (from transformers[onnx]==4.16.2->-r requirements.txt (line 4)) (0.12.1)\n",
      "Requirement already satisfied: filelock in /opt/venv/lib/python3.8/site-packages (from transformers[onnx]==4.16.2->-r requirements.txt (line 4)) (3.8.0)\n",
      "Requirement already satisfied: onnxruntime-tools>=1.4.2 in /opt/venv/lib/python3.8/site-packages (from transformers[onnx]==4.16.2->-r requirements.txt (line 4)) (1.7.0)\n",
      "Requirement already satisfied: tf2onnx in /opt/venv/lib/python3.8/site-packages (from transformers[onnx]==4.16.2->-r requirements.txt (line 4)) (1.12.0)\n",
      "Requirement already satisfied: onnxruntime>=1.4.0 in /opt/venv/lib/python3.8/site-packages (from transformers[onnx]==4.16.2->-r requirements.txt (line 4)) (1.12.1)\n",
      "Requirement already satisfied: onnxconverter-common in /opt/venv/lib/python3.8/site-packages (from transformers[onnx]==4.16.2->-r requirements.txt (line 4)) (1.12.1)\n",
      "Requirement already satisfied: typing-extensions>=3.7.4.3 in /opt/venv/lib/python3.8/site-packages (from huggingface-hub<1.0.0,>=0.1.0->datasets==1.18.3->-r requirements.txt (line 3)) (4.3.0)\n",
      "Requirement already satisfied: sympy in /opt/venv/lib/python3.8/site-packages (from onnxruntime>=1.4.0->transformers[onnx]==4.16.2->-r requirements.txt (line 4)) (1.10.1)\n",
      "Requirement already satisfied: flatbuffers in /opt/venv/lib/python3.8/site-packages (from onnxruntime>=1.4.0->transformers[onnx]==4.16.2->-r requirements.txt (line 4)) (1.12)\n",
      "Requirement already satisfied: protobuf in /opt/venv/lib/python3.8/site-packages (from onnxruntime>=1.4.0->transformers[onnx]==4.16.2->-r requirements.txt (line 4)) (3.20.1)\n",
      "Requirement already satisfied: coloredlogs in /opt/venv/lib/python3.8/site-packages (from onnxruntime>=1.4.0->transformers[onnx]==4.16.2->-r requirements.txt (line 4)) (15.0.1)\n",
      "Requirement already satisfied: py-cpuinfo in /opt/venv/lib/python3.8/site-packages (from onnxruntime-tools>=1.4.2->transformers[onnx]==4.16.2->-r requirements.txt (line 4)) (8.0.0)\n",
      "Requirement already satisfied: onnx in /opt/venv/lib/python3.8/site-packages (from onnxruntime-tools>=1.4.2->transformers[onnx]==4.16.2->-r requirements.txt (line 4)) (1.12.0)\n",
      "Requirement already satisfied: py3nvml in /opt/venv/lib/python3.8/site-packages (from onnxruntime-tools>=1.4.2->transformers[onnx]==4.16.2->-r requirements.txt (line 4)) (0.2.7)\n",
      "Requirement already satisfied: pyparsing!=3.0.5,>=2.0.2 in /opt/venv/lib/python3.8/site-packages (from packaging->datasets==1.18.3->-r requirements.txt (line 3)) (2.4.7)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in /opt/venv/lib/python3.8/site-packages (from requests>=2.19.0->datasets==1.18.3->-r requirements.txt (line 3)) (2022.6.15)\n",
      "Requirement already satisfied: charset-normalizer<3,>=2 in /opt/venv/lib/python3.8/site-packages (from requests>=2.19.0->datasets==1.18.3->-r requirements.txt (line 3)) (2.1.0)\n",
      "Requirement already satisfied: idna<4,>=2.5 in /opt/venv/lib/python3.8/site-packages (from requests>=2.19.0->datasets==1.18.3->-r requirements.txt (line 3)) (3.3)\n",
      "Requirement already satisfied: urllib3<1.27,>=1.21.1 in /opt/venv/lib/python3.8/site-packages (from requests>=2.19.0->datasets==1.18.3->-r requirements.txt (line 3)) (1.26.11)\n",
      "Requirement already satisfied: aiosignal>=1.1.2 in /opt/venv/lib/python3.8/site-packages (from aiohttp->datasets==1.18.3->-r requirements.txt (line 3)) (1.2.0)\n",
      "Requirement already satisfied: attrs>=17.3.0 in /opt/venv/lib/python3.8/site-packages (from aiohttp->datasets==1.18.3->-r requirements.txt (line 3)) (22.1.0)\n",
      "Requirement already satisfied: yarl<2.0,>=1.0 in /opt/venv/lib/python3.8/site-packages (from aiohttp->datasets==1.18.3->-r requirements.txt (line 3)) (1.8.1)\n",
      "Requirement already satisfied: frozenlist>=1.1.1 in /opt/venv/lib/python3.8/site-packages (from aiohttp->datasets==1.18.3->-r requirements.txt (line 3)) (1.3.1)\n",
      "Requirement already satisfied: async-timeout<5.0,>=4.0.0a3 in /opt/venv/lib/python3.8/site-packages (from aiohttp->datasets==1.18.3->-r requirements.txt (line 3)) (4.0.2)\n",
      "Requirement already satisfied: multidict<7.0,>=4.5 in /opt/venv/lib/python3.8/site-packages (from aiohttp->datasets==1.18.3->-r requirements.txt (line 3)) (6.0.2)\n",
      "Requirement already satisfied: pytz>=2020.1 in /opt/venv/lib/python3.8/site-packages (from pandas->datasets==1.18.3->-r requirements.txt (line 3)) (2022.2.1)\n",
      "Requirement already satisfied: python-dateutil>=2.8.1 in /opt/venv/lib/python3.8/site-packages (from pandas->datasets==1.18.3->-r requirements.txt (line 3)) (2.8.2)\n",
      "Requirement already satisfied: six in /opt/venv/lib/python3.8/site-packages (from sacremoses->transformers[onnx]==4.16.2->-r requirements.txt (line 4)) (1.16.0)\n",
      "Requirement already satisfied: click in /opt/venv/lib/python3.8/site-packages (from sacremoses->transformers[onnx]==4.16.2->-r requirements.txt (line 4)) (8.1.3)\n",
      "Requirement already satisfied: joblib in /opt/venv/lib/python3.8/site-packages (from sacremoses->transformers[onnx]==4.16.2->-r requirements.txt (line 4)) (1.1.0)\n",
      "Requirement already satisfied: humanfriendly>=9.1 in /opt/venv/lib/python3.8/site-packages (from coloredlogs->onnxruntime>=1.4.0->transformers[onnx]==4.16.2->-r requirements.txt (line 4)) (10.0)\n",
      "Requirement already satisfied: xmltodict in /opt/venv/lib/python3.8/site-packages (from py3nvml->onnxruntime-tools>=1.4.2->transformers[onnx]==4.16.2->-r requirements.txt (line 4)) (0.13.0)\n",
      "Requirement already satisfied: mpmath>=0.19 in /opt/venv/lib/python3.8/site-packages (from sympy->onnxruntime>=1.4.0->transformers[onnx]==4.16.2->-r requirements.txt (line 4)) (1.2.1)\n"
     ]
    }
   ],
   "source": [
    "!pip install -r requirements.txt"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Set up Imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/venv/lib/python3.8/site-packages/tqdm/auto.py:22: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    }
   ],
   "source": [
    "import logging\n",
    "from dataclasses import dataclass\n",
    "from dataclasses import field\n",
    "from typing import Optional\n",
    "import torch\n",
    "from trainer_qa import QuestionAnsweringTrainer\n",
    "from transformers import HfArgumentParser\n",
    "from transformers import TrainingArguments\n",
    "from transformers.utils import check_min_version\n",
    "from transformers.utils.versions import require_version"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Set up Idiom Imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "from idiom.ml.torch import setup_for_evaluation\n",
    "from idiom.ml.torch import setup_for_export\n",
    "from idiom.ml.torch import setup_for_tuning"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Set up Imports from support scripts "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "from bert_args import ModelArguments, IdiomMLArguments, DataTrainingArguments\n",
    "from trainer_support import get_trainer_support"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Version Sanity Checks"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Will error if the minimal version of Transformers is not installed. Remove at your own risks.\n",
    "check_min_version(\"4.16.2\")\n",
    "\n",
    "require_version(\n",
    "    \"datasets>=1.8.0\",\n",
    "    \"To fix: pip install -r examples/pytorch/question-answering/requirements.txt\",\n",
    ")\n",
    "\n",
    "logger = logging.getLogger(__name__)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "BERT fine-tuning and evaluation is parameterized with many argments, most of them use their default values. \n",
    "\n",
    "The arguments that are tailored for this notebook are available the the JSON file, ``tiny-bert-args.json``. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ModelArguments(model_name_or_path='mrm8488/bert-tiny-finetuned-squadv2', config_name=None, tokenizer_name=None, cache_dir=None, model_revision='main', use_auth_token=False), \n",
      "IdiomMLArguments(do_envise_eval=True, finetune_with_dft=True, finetune_with_ept=False, idiom_ml_seed=42, setup_for_export=True), \n",
      "DataTrainingArguments(dataset_name='squad_v2', dataset_config_name=None, train_file=None, validation_file=None, test_file=None, overwrite_cache=False, preprocessing_num_workers=None, max_seq_length=384, pad_to_max_length=True, max_train_samples=None, max_eval_samples=None, max_predict_samples=None, version_2_with_negative=True, null_score_diff_threshold=0.0, doc_stride=128, n_best_size=20, max_answer_length=30), \n",
      "TrainingArguments(\n",
      "_n_gpu=1,\n",
      "adafactor=False,\n",
      "adam_beta1=0.9,\n",
      "adam_beta2=0.999,\n",
      "adam_epsilon=1e-08,\n",
      "bf16=False,\n",
      "bf16_full_eval=False,\n",
      "dataloader_drop_last=False,\n",
      "dataloader_num_workers=0,\n",
      "dataloader_pin_memory=True,\n",
      "ddp_bucket_cap_mb=None,\n",
      "ddp_find_unused_parameters=None,\n",
      "debug=[],\n",
      "deepspeed=None,\n",
      "disable_tqdm=False,\n",
      "do_eval=True,\n",
      "do_predict=False,\n",
      "do_train=True,\n",
      "eval_accumulation_steps=None,\n",
      "eval_steps=None,\n",
      "evaluation_strategy=IntervalStrategy.NO,\n",
      "fp16=False,\n",
      "fp16_backend=auto,\n",
      "fp16_full_eval=False,\n",
      "fp16_opt_level=O1,\n",
      "gradient_accumulation_steps=1,\n",
      "gradient_checkpointing=False,\n",
      "greater_is_better=None,\n",
      "group_by_length=False,\n",
      "half_precision_backend=auto,\n",
      "hub_model_id=None,\n",
      "hub_strategy=HubStrategy.EVERY_SAVE,\n",
      "hub_token=<HUB_TOKEN>,\n",
      "ignore_data_skip=False,\n",
      "label_names=None,\n",
      "label_smoothing_factor=0.0,\n",
      "learning_rate=1e-06,\n",
      "length_column_name=length,\n",
      "load_best_model_at_end=False,\n",
      "local_rank=-1,\n",
      "log_level=-1,\n",
      "log_level_replica=-1,\n",
      "log_on_each_node=True,\n",
      "logging_dir=tune_output/runs/Aug19_17-25-15_cf368f8441ee,\n",
      "logging_first_step=False,\n",
      "logging_nan_inf_filter=True,\n",
      "logging_steps=1000,\n",
      "logging_strategy=IntervalStrategy.STEPS,\n",
      "lr_scheduler_type=SchedulerType.LINEAR,\n",
      "max_grad_norm=1,\n",
      "max_steps=-1,\n",
      "metric_for_best_model=None,\n",
      "mp_parameters=,\n",
      "no_cuda=False,\n",
      "num_train_epochs=1,\n",
      "optim=OptimizerNames.ADAMW_HF,\n",
      "output_dir=tune_output,\n",
      "overwrite_output_dir=True,\n",
      "past_index=-1,\n",
      "per_device_eval_batch_size=32,\n",
      "per_device_train_batch_size=12,\n",
      "prediction_loss_only=False,\n",
      "push_to_hub=False,\n",
      "push_to_hub_model_id=None,\n",
      "push_to_hub_organization=None,\n",
      "push_to_hub_token=<PUSH_TO_HUB_TOKEN>,\n",
      "remove_unused_columns=True,\n",
      "report_to=[],\n",
      "resume_from_checkpoint=None,\n",
      "run_name=tune_output,\n",
      "save_on_each_node=False,\n",
      "save_steps=1000,\n",
      "save_strategy=IntervalStrategy.STEPS,\n",
      "save_total_limit=None,\n",
      "seed=42,\n",
      "sharded_ddp=[],\n",
      "skip_memory_metrics=True,\n",
      "tf32=None,\n",
      "tpu_metrics_debug=False,\n",
      "tpu_num_cores=None,\n",
      "use_legacy_prediction_loop=False,\n",
      "warmup_ratio=0.0,\n",
      "warmup_steps=900,\n",
      "weight_decay=0.0,\n",
      "xpu_backend=None,\n",
      ")\n"
     ]
    }
   ],
   "source": [
    "# We now keep distinct sets of args, for a cleaner separation of concerns.\n",
    "parser = HfArgumentParser(\n",
    "    (\n",
    "        ModelArguments,\n",
    "        IdiomMLArguments,\n",
    "        DataTrainingArguments,\n",
    "        TrainingArguments,\n",
    "    )\n",
    ")\n",
    "(\n",
    "    model_args,\n",
    "    idiom_ml_args,\n",
    "    data_args,\n",
    "    training_args,\n",
    ") = parser.parse_json_file(json_file=\"tiny-bert-args.json\")\n",
    "# added\n",
    "training_args._n_gpu = 1  # force this\n",
    "print(f'{model_args}, \\n{idiom_ml_args}, \\n{data_args}, \\n{training_args}')\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The notebook needs support functions such as model and tokenizer download, training and evaluation datasets, and pre- and post-processing functions. \n",
    "All of these support functions have been placed outside the notebook.\n",
    "\n",
    "We just fetch them below."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "08/19/2022 17:25:15 - WARNING - __main__ - Process rank: -1, device: cuda:0, n_gpu: 1distributed training: False, 16-bits training: False\n",
      "08/19/2022 17:25:15 - INFO - __main__ - Training/evaluation parameters TrainingArguments(\n",
      "_n_gpu=1,\n",
      "adafactor=False,\n",
      "adam_beta1=0.9,\n",
      "adam_beta2=0.999,\n",
      "adam_epsilon=1e-08,\n",
      "bf16=False,\n",
      "bf16_full_eval=False,\n",
      "dataloader_drop_last=False,\n",
      "dataloader_num_workers=0,\n",
      "dataloader_pin_memory=True,\n",
      "ddp_bucket_cap_mb=None,\n",
      "ddp_find_unused_parameters=None,\n",
      "debug=[],\n",
      "deepspeed=None,\n",
      "disable_tqdm=False,\n",
      "do_eval=True,\n",
      "do_predict=False,\n",
      "do_train=True,\n",
      "eval_accumulation_steps=None,\n",
      "eval_steps=None,\n",
      "evaluation_strategy=IntervalStrategy.NO,\n",
      "fp16=False,\n",
      "fp16_backend=auto,\n",
      "fp16_full_eval=False,\n",
      "fp16_opt_level=O1,\n",
      "gradient_accumulation_steps=1,\n",
      "gradient_checkpointing=False,\n",
      "greater_is_better=None,\n",
      "group_by_length=False,\n",
      "half_precision_backend=auto,\n",
      "hub_model_id=None,\n",
      "hub_strategy=HubStrategy.EVERY_SAVE,\n",
      "hub_token=<HUB_TOKEN>,\n",
      "ignore_data_skip=False,\n",
      "label_names=None,\n",
      "label_smoothing_factor=0.0,\n",
      "learning_rate=1e-06,\n",
      "length_column_name=length,\n",
      "load_best_model_at_end=False,\n",
      "local_rank=-1,\n",
      "log_level=-1,\n",
      "log_level_replica=-1,\n",
      "log_on_each_node=True,\n",
      "logging_dir=tune_output/runs/Aug19_17-25-15_cf368f8441ee,\n",
      "logging_first_step=False,\n",
      "logging_nan_inf_filter=True,\n",
      "logging_steps=1000,\n",
      "logging_strategy=IntervalStrategy.STEPS,\n",
      "lr_scheduler_type=SchedulerType.LINEAR,\n",
      "max_grad_norm=1,\n",
      "max_steps=-1,\n",
      "metric_for_best_model=None,\n",
      "mp_parameters=,\n",
      "no_cuda=False,\n",
      "num_train_epochs=1,\n",
      "optim=OptimizerNames.ADAMW_HF,\n",
      "output_dir=tune_output,\n",
      "overwrite_output_dir=True,\n",
      "past_index=-1,\n",
      "per_device_eval_batch_size=32,\n",
      "per_device_train_batch_size=12,\n",
      "prediction_loss_only=False,\n",
      "push_to_hub=False,\n",
      "push_to_hub_model_id=None,\n",
      "push_to_hub_organization=None,\n",
      "push_to_hub_token=<PUSH_TO_HUB_TOKEN>,\n",
      "remove_unused_columns=True,\n",
      "report_to=[],\n",
      "resume_from_checkpoint=None,\n",
      "run_name=tune_output,\n",
      "save_on_each_node=False,\n",
      "save_steps=1000,\n",
      "save_strategy=IntervalStrategy.STEPS,\n",
      "save_total_limit=None,\n",
      "seed=42,\n",
      "sharded_ddp=[],\n",
      "skip_memory_metrics=True,\n",
      "tf32=None,\n",
      "tpu_metrics_debug=False,\n",
      "tpu_num_cores=None,\n",
      "use_legacy_prediction_loop=False,\n",
      "warmup_ratio=0.0,\n",
      "warmup_steps=900,\n",
      "weight_decay=0.0,\n",
      "xpu_backend=None,\n",
      ")\n",
      "08/19/2022 17:25:15 - INFO - __main__ - idiom_ml_seed: 42\n",
      "08/19/2022 17:25:15 - INFO - datasets.builder - No config specified, defaulting to first: squad_v2/squad_v2\n",
      "08/19/2022 17:25:15 - INFO - datasets.info - Loading Dataset Infos from /home/auro/.cache/huggingface/modules/datasets_modules/datasets/squad_v2/09187c73c1b837c95d9a249cd97c2c3f1cebada06efe667b4427714b27639b1d\n",
      "08/19/2022 17:25:15 - INFO - datasets.builder - Overwrite dataset info from restored data version.\n",
      "08/19/2022 17:25:15 - INFO - datasets.info - Loading Dataset info from /home/auro/.cache/huggingface/datasets/squad_v2/squad_v2/2.0.0/09187c73c1b837c95d9a249cd97c2c3f1cebada06efe667b4427714b27639b1d\n",
      "08/19/2022 17:25:15 - WARNING - datasets.builder - Reusing dataset squad_v2 (/home/auro/.cache/huggingface/datasets/squad_v2/squad_v2/2.0.0/09187c73c1b837c95d9a249cd97c2c3f1cebada06efe667b4427714b27639b1d)\n",
      "08/19/2022 17:25:15 - INFO - datasets.info - Loading Dataset info from /home/auro/.cache/huggingface/datasets/squad_v2/squad_v2/2.0.0/09187c73c1b837c95d9a249cd97c2c3f1cebada06efe667b4427714b27639b1d\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|█████████████████████████████████████████████████████████████████████| 2/2 [00:00<00:00, 456.03it/s]\n",
      "[INFO|configuration_utils.py:644] 2022-08-19 17:25:15,686 >> loading configuration file https://huggingface.co/mrm8488/bert-tiny-finetuned-squadv2/resolve/main/config.json from cache at /home/auro/.cache/huggingface/transformers/1c9c47debcf1ea704edc79a69cba3adee79cab3027129d23952abb913d834dc6.21458fa63aa73ccb6cf8f15144ae7279582dfa5bf1b3c4c7091f60b0a047af05\n",
      "[INFO|configuration_utils.py:680] 2022-08-19 17:25:15,688 >> Model config BertConfig {\n",
      "  \"_name_or_path\": \"mrm8488/bert-tiny-finetuned-squadv2\",\n",
      "  \"architectures\": [\n",
      "    \"BertForQuestionAnswering\"\n",
      "  ],\n",
      "  \"attention_probs_dropout_prob\": 0.1,\n",
      "  \"classifier_dropout\": null,\n",
      "  \"hidden_act\": \"gelu\",\n",
      "  \"hidden_dropout_prob\": 0.1,\n",
      "  \"hidden_size\": 128,\n",
      "  \"initializer_range\": 0.02,\n",
      "  \"intermediate_size\": 512,\n",
      "  \"layer_norm_eps\": 1e-12,\n",
      "  \"max_position_embeddings\": 512,\n",
      "  \"model_type\": \"bert\",\n",
      "  \"num_attention_heads\": 2,\n",
      "  \"num_hidden_layers\": 2,\n",
      "  \"output_past\": true,\n",
      "  \"pad_token_id\": 0,\n",
      "  \"position_embedding_type\": \"absolute\",\n",
      "  \"transformers_version\": \"4.16.2\",\n",
      "  \"type_vocab_size\": 2,\n",
      "  \"use_cache\": true,\n",
      "  \"vocab_size\": 30522\n",
      "}\n",
      "\n",
      "[INFO|configuration_utils.py:644] 2022-08-19 17:25:15,872 >> loading configuration file https://huggingface.co/mrm8488/bert-tiny-finetuned-squadv2/resolve/main/config.json from cache at /home/auro/.cache/huggingface/transformers/1c9c47debcf1ea704edc79a69cba3adee79cab3027129d23952abb913d834dc6.21458fa63aa73ccb6cf8f15144ae7279582dfa5bf1b3c4c7091f60b0a047af05\n",
      "[INFO|configuration_utils.py:680] 2022-08-19 17:25:15,874 >> Model config BertConfig {\n",
      "  \"_name_or_path\": \"mrm8488/bert-tiny-finetuned-squadv2\",\n",
      "  \"architectures\": [\n",
      "    \"BertForQuestionAnswering\"\n",
      "  ],\n",
      "  \"attention_probs_dropout_prob\": 0.1,\n",
      "  \"classifier_dropout\": null,\n",
      "  \"hidden_act\": \"gelu\",\n",
      "  \"hidden_dropout_prob\": 0.1,\n",
      "  \"hidden_size\": 128,\n",
      "  \"initializer_range\": 0.02,\n",
      "  \"intermediate_size\": 512,\n",
      "  \"layer_norm_eps\": 1e-12,\n",
      "  \"max_position_embeddings\": 512,\n",
      "  \"model_type\": \"bert\",\n",
      "  \"num_attention_heads\": 2,\n",
      "  \"num_hidden_layers\": 2,\n",
      "  \"output_past\": true,\n",
      "  \"pad_token_id\": 0,\n",
      "  \"position_embedding_type\": \"absolute\",\n",
      "  \"transformers_version\": \"4.16.2\",\n",
      "  \"type_vocab_size\": 2,\n",
      "  \"use_cache\": true,\n",
      "  \"vocab_size\": 30522\n",
      "}\n",
      "\n",
      "[INFO|tokenization_utils_base.py:1771] 2022-08-19 17:25:16,370 >> loading file https://huggingface.co/mrm8488/bert-tiny-finetuned-squadv2/resolve/main/vocab.txt from cache at /home/auro/.cache/huggingface/transformers/453b49185fedfddb93809fc19cb1549f313cc2686b1a81fc2fd9298174836989.d789d64ebfe299b0e416afc4a169632f903f693095b4629a7ea271d5a0cf2c99\n",
      "[INFO|tokenization_utils_base.py:1771] 2022-08-19 17:25:16,371 >> loading file https://huggingface.co/mrm8488/bert-tiny-finetuned-squadv2/resolve/main/tokenizer.json from cache at None\n",
      "[INFO|tokenization_utils_base.py:1771] 2022-08-19 17:25:16,372 >> loading file https://huggingface.co/mrm8488/bert-tiny-finetuned-squadv2/resolve/main/added_tokens.json from cache at None\n",
      "[INFO|tokenization_utils_base.py:1771] 2022-08-19 17:25:16,373 >> loading file https://huggingface.co/mrm8488/bert-tiny-finetuned-squadv2/resolve/main/special_tokens_map.json from cache at /home/auro/.cache/huggingface/transformers/92a2a4517aa2df06f5328fb21b6ecfb97ce7d85c5bd283593af7460e8063ffd4.dd8bd9bfd3664b530ea4e645105f557769387b3da9f79bdb55ed556bdd80611d\n",
      "[INFO|tokenization_utils_base.py:1771] 2022-08-19 17:25:16,374 >> loading file https://huggingface.co/mrm8488/bert-tiny-finetuned-squadv2/resolve/main/tokenizer_config.json from cache at /home/auro/.cache/huggingface/transformers/7c96e880794dd2a24177c02938b78abc07bb4026ca22037286ae52254afdbcf2.7d8cf5940d60559bc588a922cc36816803bd6aa4db1f2dd48db71df501ac6ea3\n",
      "[INFO|configuration_utils.py:644] 2022-08-19 17:25:16,452 >> loading configuration file https://huggingface.co/mrm8488/bert-tiny-finetuned-squadv2/resolve/main/config.json from cache at /home/auro/.cache/huggingface/transformers/1c9c47debcf1ea704edc79a69cba3adee79cab3027129d23952abb913d834dc6.21458fa63aa73ccb6cf8f15144ae7279582dfa5bf1b3c4c7091f60b0a047af05\n",
      "[INFO|configuration_utils.py:680] 2022-08-19 17:25:16,454 >> Model config BertConfig {\n",
      "  \"_name_or_path\": \"mrm8488/bert-tiny-finetuned-squadv2\",\n",
      "  \"architectures\": [\n",
      "    \"BertForQuestionAnswering\"\n",
      "  ],\n",
      "  \"attention_probs_dropout_prob\": 0.1,\n",
      "  \"classifier_dropout\": null,\n",
      "  \"hidden_act\": \"gelu\",\n",
      "  \"hidden_dropout_prob\": 0.1,\n",
      "  \"hidden_size\": 128,\n",
      "  \"initializer_range\": 0.02,\n",
      "  \"intermediate_size\": 512,\n",
      "  \"layer_norm_eps\": 1e-12,\n",
      "  \"max_position_embeddings\": 512,\n",
      "  \"model_type\": \"bert\",\n",
      "  \"num_attention_heads\": 2,\n",
      "  \"num_hidden_layers\": 2,\n",
      "  \"output_past\": true,\n",
      "  \"pad_token_id\": 0,\n",
      "  \"position_embedding_type\": \"absolute\",\n",
      "  \"transformers_version\": \"4.16.2\",\n",
      "  \"type_vocab_size\": 2,\n",
      "  \"use_cache\": true,\n",
      "  \"vocab_size\": 30522\n",
      "}\n",
      "\n",
      "[INFO|configuration_utils.py:644] 2022-08-19 17:25:16,555 >> loading configuration file https://huggingface.co/mrm8488/bert-tiny-finetuned-squadv2/resolve/main/config.json from cache at /home/auro/.cache/huggingface/transformers/1c9c47debcf1ea704edc79a69cba3adee79cab3027129d23952abb913d834dc6.21458fa63aa73ccb6cf8f15144ae7279582dfa5bf1b3c4c7091f60b0a047af05\n",
      "[INFO|configuration_utils.py:680] 2022-08-19 17:25:16,558 >> Model config BertConfig {\n",
      "  \"_name_or_path\": \"mrm8488/bert-tiny-finetuned-squadv2\",\n",
      "  \"architectures\": [\n",
      "    \"BertForQuestionAnswering\"\n",
      "  ],\n",
      "  \"attention_probs_dropout_prob\": 0.1,\n",
      "  \"classifier_dropout\": null,\n",
      "  \"hidden_act\": \"gelu\",\n",
      "  \"hidden_dropout_prob\": 0.1,\n",
      "  \"hidden_size\": 128,\n",
      "  \"initializer_range\": 0.02,\n",
      "  \"intermediate_size\": 512,\n",
      "  \"layer_norm_eps\": 1e-12,\n",
      "  \"max_position_embeddings\": 512,\n",
      "  \"model_type\": \"bert\",\n",
      "  \"num_attention_heads\": 2,\n",
      "  \"num_hidden_layers\": 2,\n",
      "  \"output_past\": true,\n",
      "  \"pad_token_id\": 0,\n",
      "  \"position_embedding_type\": \"absolute\",\n",
      "  \"transformers_version\": \"4.16.2\",\n",
      "  \"type_vocab_size\": 2,\n",
      "  \"use_cache\": true,\n",
      "  \"vocab_size\": 30522\n",
      "}\n",
      "\n",
      "[INFO|modeling_utils.py:1427] 2022-08-19 17:25:16,659 >> loading weights file https://huggingface.co/mrm8488/bert-tiny-finetuned-squadv2/resolve/main/pytorch_model.bin from cache at /home/auro/.cache/huggingface/transformers/f093b3e476e9145f97817223ffecf3e4385416b6f77d05dbd2181a70d17a01d7.4abee409e81e850e9dcabdff21722c70ffae48c5e4dfd6c1ea863e313becbf24\n",
      "[INFO|modeling_utils.py:1694] 2022-08-19 17:25:16,757 >> All model checkpoint weights were used when initializing BertForQuestionAnswering.\n",
      "\n",
      "[INFO|modeling_utils.py:1702] 2022-08-19 17:25:16,765 >> All the weights of BertForQuestionAnswering were initialized from the model checkpoint at mrm8488/bert-tiny-finetuned-squadv2.\n",
      "If your task is similar to the task the model of the checkpoint was trained on, you can already use BertForQuestionAnswering for predictions without further training.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "08/19/2022 17:25:16 - WARNING - datasets.fingerprint - Parameter 'function'=<function get_trainer_support.<locals>.prepare_train_features at 0x7fdc800d71f0> of the transform datasets.arrow_dataset.Dataset._map_single couldn't be hashed properly, a random hash was used instead. Make sure your transforms and parameters are serializable with pickle or dill for the dataset fingerprinting and caching to work. If you reuse this transform, the caching mechanism will consider it to be different from the previous calls and recompute everything. This warning is only showed once. Subsequent hashing failures won't be showed.\n",
      "08/19/2022 17:25:16 - WARNING - datasets.arrow_dataset - Loading cached processed dataset at /home/auro/.cache/huggingface/datasets/squad_v2/squad_v2/2.0.0/09187c73c1b837c95d9a249cd97c2c3f1cebada06efe667b4427714b27639b1d/cache-1c80317fa3b1799d.arrow\n",
      "08/19/2022 17:25:16 - INFO - datasets.fingerprint - Parameter 'function'=<function get_trainer_support.<locals>.prepare_validation_features at 0x7fdc800d7310> of the transform datasets.arrow_dataset.Dataset._map_single couldn't be hashed properly, a random hash was used instead.\n",
      "08/19/2022 17:25:16 - WARNING - datasets.arrow_dataset - Loading cached processed dataset at /home/auro/.cache/huggingface/datasets/squad_v2/squad_v2/2.0.0/09187c73c1b837c95d9a249cd97c2c3f1cebada06efe667b4427714b27639b1d/cache-bdd640fb06671ad1.arrow\n"
     ]
    }
   ],
   "source": [
    "model_params, all_datasets, other_params \\\n",
    "    = get_trainer_support(model_args, idiom_ml_args, data_args, training_args, logger)\n",
    "\n",
    "trainer, model = model_params['trainer'], model_params['model']\n",
    "eval_dataset, train_dataset  = all_datasets['eval_dataset'], all_datasets['train_dataset']\n",
    "eval_examples = all_datasets['eval_examples']\n",
    "tokenizer, data_collator = other_params['tokenizer'], other_params['data_collator']\n",
    "post_processing_function  = other_params['post_processing_function']\n",
    "compute_metrics = other_params['compute_metrics']\n",
    "last_checkpoint = other_params['last_checkpoint']\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "First, we evaluate the model as we received it, i.e., with FP32 precision.\n",
    "\n",
    "The accuracy metrics we track is `eval_exact`, the Exact Match. \n",
    "\n",
    "Exact Match is a match/no-match  measure of whether the evaluation output matches the\n",
    "ground truth answer exactly. This is a strict metric."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Evaluate out-of-the-box accuracy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[INFO|trainer.py:553] 2022-08-19 17:25:20,775 >> The following columns in the evaluation set  don't have a corresponding argument in `BertForQuestionAnswering.forward` and have been ignored: offset_mapping, example_id.\n",
      "[INFO|trainer.py:2340] 2022-08-19 17:25:20,782 >> ***** Running Evaluation *****\n",
      "[INFO|trainer.py:2342] 2022-08-19 17:25:20,783 >>   Num examples = 12106\n",
      "[INFO|trainer.py:2345] 2022-08-19 17:25:20,783 >>   Batch size = 32\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='1137' max='379' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [379/379 12:42]\n",
       "    </div>\n",
       "    "
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "08/19/2022 17:25:42 - INFO - utils_qa - Post-processing 11873 example predictions split into 12106 features.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|█████████████████████████████████████████████████████████████| 11873/11873 [00:36<00:00, 329.53it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "08/19/2022 17:26:18 - INFO - utils_qa - Saving predictions to tune_output/eval_predictions.json.\n",
      "08/19/2022 17:26:18 - INFO - utils_qa - Saving nbest_preds to tune_output/eval_nbest_predictions.json.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "08/19/2022 17:26:21 - INFO - utils_qa - Saving null_odds to tune_output/eval_null_odds.json.\n",
      "08/19/2022 17:26:23 - INFO - datasets.metric - Removing /home/auro/.cache/huggingface/metrics/squad_v2/default/default_experiment-1-0.arrow\n",
      "***** Out of the Box eval matrics metrics *****\n",
      "  eval_HasAns_exact      =  9.3455\n",
      "  eval_HasAns_f1         = 11.6074\n",
      "  eval_HasAns_total      =    5928\n",
      "  eval_NoAns_exact       = 87.7376\n",
      "  eval_NoAns_f1          = 87.7376\n",
      "  eval_NoAns_total       =    5945\n",
      "  eval_best_exact        = 50.0969\n",
      "  eval_best_exact_thresh =     0.0\n",
      "  eval_best_f1           = 50.2419\n",
      "  eval_best_f1_thresh    =     0.0\n",
      "  eval_exact             = 48.5977\n",
      "  eval_f1                =  49.727\n",
      "  eval_total             =   11873\n"
     ]
    }
   ],
   "source": [
    "# Out of the Box Model Evaluation\n",
    "if training_args.do_eval:\n",
    "    oob_metrics = trainer.evaluate()\n",
    "    trainer.log_metrics(\"Out of the Box eval matrics\", oob_metrics)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Next, we estimate the accuracy on Envise. Note, this is an estimate using Envise precision and the metric `eval_ecact` is expected to be lower that the original FP32 accuracy."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Evaluate for Envise Precision"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "08/19/2022 17:26:23 - INFO - __main__ - *** Envise Eval ***\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[INFO|trainer.py:553] 2022-08-19 17:26:23,978 >> The following columns in the evaluation set  don't have a corresponding argument in `BertForQuestionAnswering.forward` and have been ignored: offset_mapping, example_id.\n",
      "[INFO|trainer.py:2340] 2022-08-19 17:26:23,980 >> ***** Running Evaluation *****\n",
      "[INFO|trainer.py:2342] 2022-08-19 17:26:23,981 >>   Num examples = 12106\n",
      "[INFO|trainer.py:2345] 2022-08-19 17:26:23,982 >>   Batch size = 32\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "08/19/2022 17:27:02 - INFO - utils_qa - Post-processing 11873 example predictions split into 12106 features.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|█████████████████████████████████████████████████████████████| 11873/11873 [00:36<00:00, 325.90it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "08/19/2022 17:27:39 - INFO - utils_qa - Saving predictions to tune_output/eval_predictions.json.\n",
      "08/19/2022 17:27:39 - INFO - utils_qa - Saving nbest_preds to tune_output/eval_nbest_predictions.json.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "08/19/2022 17:27:41 - INFO - utils_qa - Saving null_odds to tune_output/eval_null_odds.json.\n",
      "08/19/2022 17:27:44 - INFO - datasets.metric - Removing /home/auro/.cache/huggingface/metrics/squad_v2/default/default_experiment-1-0.arrow\n",
      "***** eval metrics *****\n",
      "  eval_HasAns_exact      =  7.6923\n",
      "  eval_HasAns_f1         = 10.5563\n",
      "  eval_HasAns_total      =    5928\n",
      "  eval_NoAns_exact       = 85.7023\n",
      "  eval_NoAns_f1          = 85.7023\n",
      "  eval_NoAns_total       =    5945\n",
      "  eval_best_exact        =   50.08\n",
      "  eval_best_exact_thresh =     0.0\n",
      "  eval_best_f1           = 50.1101\n",
      "  eval_best_f1_thresh    =     0.0\n",
      "  eval_exact             = 46.7531\n",
      "  eval_f1                = 48.1831\n",
      "  eval_samples           =   12106\n",
      "  eval_total             =   11873\n"
     ]
    }
   ],
   "source": [
    "# Envise Evaluation\n",
    "if idiom_ml_args.do_envise_eval:\n",
    "    setup_for_evaluation(model)\n",
    "    \n",
    "if training_args.do_eval:\n",
    "    logger.info(\"*** Envise Eval ***\")\n",
    "    metrics = trainer.evaluate()\n",
    "\n",
    "    max_eval_samples = (\n",
    "        data_args.max_eval_samples\n",
    "        if data_args.max_eval_samples is not None\n",
    "        else len(eval_dataset)\n",
    "    )\n",
    "    metrics[\"eval_samples\"] = min(max_eval_samples, len(eval_dataset))\n",
    "\n",
    "    trainer.log_metrics(\"eval\", metrics)\n",
    "    trainer.save_metrics(\"eval\", metrics)\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Fine-tuning"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Computing outputs of first model (source)...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/idiom-ml/idiom/ml/torch/replace/replace.py:179: UserWarning: Registering BFloat16 hooks on non-PyTorch module Linear. The effects on this module of truncating tensors to BFloat16 precison on this module are unknown.\n",
      "  warnings.warn(msg)\n",
      "/idiom-ml/idiom/ml/torch/replace/replace.py:179: UserWarning: Registering BFloat16 hooks on non-PyTorch module Tanh. The effects on this module of truncating tensors to BFloat16 precison on this module are unknown.\n",
      "  warnings.warn(msg)\n",
      "/idiom-ml/idiom/ml/torch/replace/replace.py:179: UserWarning: Registering BFloat16 hooks on non-PyTorch module SerialMatMul4d. The effects on this module of truncating tensors to BFloat16 precison on this module are unknown.\n",
      "  warnings.warn(msg)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Computing outputs of second model (target)...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/venv/lib/python3.8/site-packages/transformers/optimization.py:306: FutureWarning: This implementation of AdamW is deprecated and will be removed in a future version. Use thePyTorch implementation torch.optim.AdamW instead, or set `no_deprecation_warning=True` to disable this warning\n",
      "  warnings.warn(\n",
      "[INFO|trainer.py:1244] 2022-08-19 17:27:47,425 >> ***** Running training *****\n",
      "[INFO|trainer.py:1245] 2022-08-19 17:27:47,425 >>   Num examples = 131422\n",
      "[INFO|trainer.py:1246] 2022-08-19 17:27:47,426 >>   Num Epochs = 1\n",
      "[INFO|trainer.py:1247] 2022-08-19 17:27:47,426 >>   Instantaneous batch size per device = 12\n",
      "[INFO|trainer.py:1248] 2022-08-19 17:27:47,427 >>   Total train batch size (w. parallel, distributed & accumulation) = 12\n",
      "[INFO|trainer.py:1249] 2022-08-19 17:27:47,427 >>   Gradient Accumulation steps = 1\n",
      "[INFO|trainer.py:1250] 2022-08-19 17:27:47,427 >>   Total optimization steps = 10952\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Computing output noise tensors...\n",
      "Registering hooks into the model...\n",
      "Successfully registered 13 hooks.\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='10952' max='10952' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [10952/10952 09:58, Epoch 1/1]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       " <tr style=\"text-align: left;\">\n",
       "      <th>Step</th>\n",
       "      <th>Training Loss</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>1000</td>\n",
       "      <td>2.969400</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2000</td>\n",
       "      <td>2.981600</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3000</td>\n",
       "      <td>2.948700</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4000</td>\n",
       "      <td>2.935600</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>5000</td>\n",
       "      <td>2.906500</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>6000</td>\n",
       "      <td>2.955400</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>7000</td>\n",
       "      <td>2.919400</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>8000</td>\n",
       "      <td>2.930000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>9000</td>\n",
       "      <td>2.935600</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>10000</td>\n",
       "      <td>2.920600</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[INFO|trainer.py:2090] 2022-08-19 17:28:50,167 >> Saving model checkpoint to tune_output/checkpoint-1000\n",
      "[INFO|configuration_utils.py:430] 2022-08-19 17:28:50,170 >> Configuration saved in tune_output/checkpoint-1000/config.json\n",
      "[INFO|modeling_utils.py:1074] 2022-08-19 17:28:50,205 >> Model weights saved in tune_output/checkpoint-1000/pytorch_model.bin\n",
      "[INFO|tokenization_utils_base.py:2074] 2022-08-19 17:28:50,207 >> tokenizer config file saved in tune_output/checkpoint-1000/tokenizer_config.json\n",
      "[INFO|tokenization_utils_base.py:2080] 2022-08-19 17:28:50,208 >> Special tokens file saved in tune_output/checkpoint-1000/special_tokens_map.json\n",
      "[INFO|trainer.py:2090] 2022-08-19 17:29:43,562 >> Saving model checkpoint to tune_output/checkpoint-2000\n",
      "[INFO|configuration_utils.py:430] 2022-08-19 17:29:43,566 >> Configuration saved in tune_output/checkpoint-2000/config.json\n",
      "[INFO|modeling_utils.py:1074] 2022-08-19 17:29:43,600 >> Model weights saved in tune_output/checkpoint-2000/pytorch_model.bin\n",
      "[INFO|tokenization_utils_base.py:2074] 2022-08-19 17:29:43,602 >> tokenizer config file saved in tune_output/checkpoint-2000/tokenizer_config.json\n",
      "[INFO|tokenization_utils_base.py:2080] 2022-08-19 17:29:43,603 >> Special tokens file saved in tune_output/checkpoint-2000/special_tokens_map.json\n",
      "[INFO|trainer.py:2090] 2022-08-19 17:30:36,895 >> Saving model checkpoint to tune_output/checkpoint-3000\n",
      "[INFO|configuration_utils.py:430] 2022-08-19 17:30:36,898 >> Configuration saved in tune_output/checkpoint-3000/config.json\n",
      "[INFO|modeling_utils.py:1074] 2022-08-19 17:30:36,931 >> Model weights saved in tune_output/checkpoint-3000/pytorch_model.bin\n",
      "[INFO|tokenization_utils_base.py:2074] 2022-08-19 17:30:36,933 >> tokenizer config file saved in tune_output/checkpoint-3000/tokenizer_config.json\n",
      "[INFO|tokenization_utils_base.py:2080] 2022-08-19 17:30:36,934 >> Special tokens file saved in tune_output/checkpoint-3000/special_tokens_map.json\n",
      "[INFO|trainer.py:2090] 2022-08-19 17:31:31,769 >> Saving model checkpoint to tune_output/checkpoint-4000\n",
      "[INFO|configuration_utils.py:430] 2022-08-19 17:31:31,773 >> Configuration saved in tune_output/checkpoint-4000/config.json\n",
      "[INFO|modeling_utils.py:1074] 2022-08-19 17:31:31,804 >> Model weights saved in tune_output/checkpoint-4000/pytorch_model.bin\n",
      "[INFO|tokenization_utils_base.py:2074] 2022-08-19 17:31:31,806 >> tokenizer config file saved in tune_output/checkpoint-4000/tokenizer_config.json\n",
      "[INFO|tokenization_utils_base.py:2080] 2022-08-19 17:31:31,807 >> Special tokens file saved in tune_output/checkpoint-4000/special_tokens_map.json\n",
      "[INFO|trainer.py:2090] 2022-08-19 17:32:25,836 >> Saving model checkpoint to tune_output/checkpoint-5000\n",
      "[INFO|configuration_utils.py:430] 2022-08-19 17:32:25,839 >> Configuration saved in tune_output/checkpoint-5000/config.json\n",
      "[INFO|modeling_utils.py:1074] 2022-08-19 17:32:25,871 >> Model weights saved in tune_output/checkpoint-5000/pytorch_model.bin\n",
      "[INFO|tokenization_utils_base.py:2074] 2022-08-19 17:32:25,872 >> tokenizer config file saved in tune_output/checkpoint-5000/tokenizer_config.json\n",
      "[INFO|tokenization_utils_base.py:2080] 2022-08-19 17:32:25,874 >> Special tokens file saved in tune_output/checkpoint-5000/special_tokens_map.json\n",
      "[INFO|trainer.py:2090] 2022-08-19 17:33:19,201 >> Saving model checkpoint to tune_output/checkpoint-6000\n",
      "[INFO|configuration_utils.py:430] 2022-08-19 17:33:19,205 >> Configuration saved in tune_output/checkpoint-6000/config.json\n",
      "[INFO|modeling_utils.py:1074] 2022-08-19 17:33:19,239 >> Model weights saved in tune_output/checkpoint-6000/pytorch_model.bin\n",
      "[INFO|tokenization_utils_base.py:2074] 2022-08-19 17:33:19,241 >> tokenizer config file saved in tune_output/checkpoint-6000/tokenizer_config.json\n",
      "[INFO|tokenization_utils_base.py:2080] 2022-08-19 17:33:19,242 >> Special tokens file saved in tune_output/checkpoint-6000/special_tokens_map.json\n",
      "[INFO|trainer.py:2090] 2022-08-19 17:34:13,594 >> Saving model checkpoint to tune_output/checkpoint-7000\n",
      "[INFO|configuration_utils.py:430] 2022-08-19 17:34:13,598 >> Configuration saved in tune_output/checkpoint-7000/config.json\n",
      "[INFO|modeling_utils.py:1074] 2022-08-19 17:34:13,628 >> Model weights saved in tune_output/checkpoint-7000/pytorch_model.bin\n",
      "[INFO|tokenization_utils_base.py:2074] 2022-08-19 17:34:13,630 >> tokenizer config file saved in tune_output/checkpoint-7000/tokenizer_config.json\n",
      "[INFO|tokenization_utils_base.py:2080] 2022-08-19 17:34:13,631 >> Special tokens file saved in tune_output/checkpoint-7000/special_tokens_map.json\n",
      "[INFO|trainer.py:2090] 2022-08-19 17:35:07,366 >> Saving model checkpoint to tune_output/checkpoint-8000\n",
      "[INFO|configuration_utils.py:430] 2022-08-19 17:35:07,370 >> Configuration saved in tune_output/checkpoint-8000/config.json\n",
      "[INFO|modeling_utils.py:1074] 2022-08-19 17:35:07,403 >> Model weights saved in tune_output/checkpoint-8000/pytorch_model.bin\n",
      "[INFO|tokenization_utils_base.py:2074] 2022-08-19 17:35:07,405 >> tokenizer config file saved in tune_output/checkpoint-8000/tokenizer_config.json\n",
      "[INFO|tokenization_utils_base.py:2080] 2022-08-19 17:35:07,406 >> Special tokens file saved in tune_output/checkpoint-8000/special_tokens_map.json\n",
      "[INFO|trainer.py:2090] 2022-08-19 17:36:02,204 >> Saving model checkpoint to tune_output/checkpoint-9000\n",
      "[INFO|configuration_utils.py:430] 2022-08-19 17:36:02,208 >> Configuration saved in tune_output/checkpoint-9000/config.json\n",
      "[INFO|modeling_utils.py:1074] 2022-08-19 17:36:02,241 >> Model weights saved in tune_output/checkpoint-9000/pytorch_model.bin\n",
      "[INFO|tokenization_utils_base.py:2074] 2022-08-19 17:36:02,243 >> tokenizer config file saved in tune_output/checkpoint-9000/tokenizer_config.json\n",
      "[INFO|tokenization_utils_base.py:2080] 2022-08-19 17:36:02,244 >> Special tokens file saved in tune_output/checkpoint-9000/special_tokens_map.json\n",
      "[INFO|trainer.py:2090] 2022-08-19 17:36:55,645 >> Saving model checkpoint to tune_output/checkpoint-10000\n",
      "[INFO|configuration_utils.py:430] 2022-08-19 17:36:55,649 >> Configuration saved in tune_output/checkpoint-10000/config.json\n",
      "[INFO|modeling_utils.py:1074] 2022-08-19 17:36:55,680 >> Model weights saved in tune_output/checkpoint-10000/pytorch_model.bin\n",
      "[INFO|tokenization_utils_base.py:2074] 2022-08-19 17:36:55,682 >> tokenizer config file saved in tune_output/checkpoint-10000/tokenizer_config.json\n",
      "[INFO|tokenization_utils_base.py:2080] 2022-08-19 17:36:55,683 >> Special tokens file saved in tune_output/checkpoint-10000/special_tokens_map.json\n",
      "[INFO|trainer.py:1473] 2022-08-19 17:37:46,050 >> \n",
      "\n",
      "Training completed. Do not forget to share your model on huggingface.co/models =)\n",
      "\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "***** train metrics *****\n",
      "  epoch                    =        1.0\n",
      "  total_flos               =   111970GF\n",
      "  train_loss               =     2.9368\n",
      "  train_runtime            = 0:09:58.62\n",
      "  train_samples            =     131422\n",
      "  train_samples_per_second =     219.54\n",
      "  train_steps_per_second   =     18.295\n"
     ]
    }
   ],
   "source": [
    "if training_args.do_train and idiom_ml_args.finetune_with_dft:\n",
    "    # prepare model to simulate training on Envise with DFT\n",
    "    trainer_dft = QuestionAnsweringTrainer(\n",
    "        model=model,\n",
    "        args=training_args,\n",
    "        train_dataset=train_dataset if training_args.do_train else None,\n",
    "        eval_dataset=eval_dataset if training_args.do_eval else None,\n",
    "        eval_examples=eval_examples if training_args.do_eval else None,\n",
    "        tokenizer=tokenizer,\n",
    "        data_collator=data_collator,\n",
    "        post_process_function=post_processing_function,\n",
    "        compute_metrics=compute_metrics,\n",
    "    )\n",
    "    train_dft_dataloader = trainer_dft.get_train_dataloader()\n",
    "    inputs_dnf = next(iter(train_dft_dataloader))\n",
    "\n",
    "    def batch_process_func(model, inputs):\n",
    "        device = next(model.parameters()).device\n",
    "        for k in inputs:\n",
    "            inputs[k] = inputs[k].to(device)\n",
    "        with torch.no_grad():\n",
    "            model(**inputs)\n",
    "\n",
    "    setup_for_tuning(\n",
    "        model,\n",
    "        inputs=inputs_dnf,\n",
    "        batch_process_func=batch_process_func,\n",
    "    )\n",
    "    del trainer_dft\n",
    "\n",
    "# fine-tuning\n",
    "if training_args.do_train:\n",
    "    checkpoint = None\n",
    "    if training_args.resume_from_checkpoint is not None:\n",
    "        checkpoint = training_args.resume_from_checkpoint\n",
    "    elif last_checkpoint is not None:\n",
    "        checkpoint = last_checkpoint\n",
    "    train_result = trainer.train(resume_from_checkpoint=checkpoint)\n",
    "\n",
    "    metrics = train_result.metrics\n",
    "    max_train_samples = (\n",
    "        data_args.max_train_samples\n",
    "        if data_args.max_train_samples is not None\n",
    "        else len(train_dataset)\n",
    "    )\n",
    "    metrics[\"train_samples\"] = min(max_train_samples, len(train_dataset))\n",
    "\n",
    "    trainer.log_metrics(\"train\", metrics)\n",
    "    trainer.save_metrics(\"train\", metrics)\n",
    "    trainer.save_state()\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Simulate Evaluation after Fine-tuning"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "08/19/2022 17:37:46 - INFO - __main__ - *** Evaluate ***\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/idiom-ml/idiom/ml/torch/replace/replace.py:179: UserWarning: Registering BFloat16 hooks on non-PyTorch module Linear. The effects on this module of truncating tensors to BFloat16 precison on this module are unknown.\n",
      "  warnings.warn(msg)\n",
      "/idiom-ml/idiom/ml/torch/replace/replace.py:179: UserWarning: Registering BFloat16 hooks on non-PyTorch module Tanh. The effects on this module of truncating tensors to BFloat16 precison on this module are unknown.\n",
      "  warnings.warn(msg)\n",
      "/idiom-ml/idiom/ml/torch/replace/replace.py:179: UserWarning: Registering BFloat16 hooks on non-PyTorch module SerialMatMul4d. The effects on this module of truncating tensors to BFloat16 precison on this module are unknown.\n",
      "  warnings.warn(msg)\n",
      "[INFO|trainer.py:553] 2022-08-19 17:37:46,069 >> The following columns in the evaluation set  don't have a corresponding argument in `BertForQuestionAnswering.forward` and have been ignored: offset_mapping, example_id.\n",
      "[INFO|trainer.py:2340] 2022-08-19 17:37:46,074 >> ***** Running Evaluation *****\n",
      "[INFO|trainer.py:2342] 2022-08-19 17:37:46,075 >>   Num examples = 12106\n",
      "[INFO|trainer.py:2345] 2022-08-19 17:37:46,075 >>   Batch size = 32\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "08/19/2022 17:38:17 - INFO - utils_qa - Post-processing 11873 example predictions split into 12106 features.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|█████████████████████████████████████████████████████████████| 11873/11873 [00:35<00:00, 330.11it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "08/19/2022 17:38:53 - INFO - utils_qa - Saving predictions to tune_output/eval_predictions.json.\n",
      "08/19/2022 17:38:53 - INFO - utils_qa - Saving nbest_preds to tune_output/eval_nbest_predictions.json.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "08/19/2022 17:38:55 - INFO - utils_qa - Saving null_odds to tune_output/eval_null_odds.json.\n",
      "08/19/2022 17:38:58 - INFO - datasets.metric - Removing /home/auro/.cache/huggingface/metrics/squad_v2/default/default_experiment-1-0.arrow\n",
      "***** eval metrics *****\n",
      "  epoch                  =     1.0\n",
      "  eval_HasAns_exact      =  6.1741\n",
      "  eval_HasAns_f1         =  8.0907\n",
      "  eval_HasAns_total      =    5928\n",
      "  eval_NoAns_exact       =  90.513\n",
      "  eval_NoAns_f1          =  90.513\n",
      "  eval_NoAns_total       =    5945\n",
      "  eval_best_exact        =   50.08\n",
      "  eval_best_exact_thresh =     0.0\n",
      "  eval_best_f1           = 50.1179\n",
      "  eval_best_f1_thresh    =     0.0\n",
      "  eval_exact             = 48.4039\n",
      "  eval_f1                = 49.3609\n",
      "  eval_samples           =   12106\n",
      "  eval_total             =   11873\n"
     ]
    }
   ],
   "source": [
    "if idiom_ml_args.do_envise_eval:\n",
    "    setup_for_evaluation(model)\n",
    "\n",
    "# Evaluation\n",
    "if training_args.do_eval:\n",
    "    logger.info(\"*** Evaluate ***\")\n",
    "    metrics = trainer.evaluate()\n",
    "\n",
    "    max_eval_samples = (\n",
    "        data_args.max_eval_samples\n",
    "        if data_args.max_eval_samples is not None\n",
    "        else len(eval_dataset)\n",
    "    )\n",
    "    metrics[\"eval_samples\"] = min(max_eval_samples, len(eval_dataset))\n",
    "\n",
    "    trainer.log_metrics(\"eval\", metrics)\n",
    "    trainer.save_metrics(\"eval\", metrics)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Export the model to ONNX"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[INFO|configuration_utils.py:430] 2022-08-19 17:40:12,869 >> Configuration saved in bert-tiny-idiom-finetuned/config.json\n",
      "[INFO|modeling_utils.py:1074] 2022-08-19 17:40:12,923 >> Model weights saved in bert-tiny-idiom-finetuned/pytorch_model.bin\n",
      "[INFO|tokenization_utils_base.py:2074] 2022-08-19 17:40:12,924 >> tokenizer config file saved in bert-tiny-idiom-finetuned/tokenizer_config.json\n",
      "[INFO|tokenization_utils_base.py:2080] 2022-08-19 17:40:12,924 >> Special tokens file saved in bert-tiny-idiom-finetuned/special_tokens_map.json\n"
     ]
    }
   ],
   "source": [
    "if idiom_ml_args.setup_for_export:\n",
    "    model = setup_for_export(model)\n",
    "    model.save_pretrained(\"bert-tiny-idiom-finetuned\")\n",
    "    tokenizer.save_pretrained(\"bert-tiny-idiom-finetuned\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using framework PyTorch: 1.10.0+cu111\n",
      "Overriding 1 configuration item(s)\n",
      "\t- use_cache -> False\n",
      "/opt/venv/lib/python3.8/site-packages/torch/onnx/utils.py:90: UserWarning: 'enable_onnx_checker' is deprecated and ignored. It will be removed in the next PyTorch release. To proceed despite ONNX checker failures, catch torch.onnx.ONNXCheckerError.\n",
      "  warnings.warn(\"'enable_onnx_checker' is deprecated and ignored. It will be removed in \"\n",
      "/opt/venv/lib/python3.8/site-packages/torch/onnx/utils.py:103: UserWarning: `use_external_data_format' is deprecated and ignored. Will be removed in next PyTorch release. The code will work as it is False if models are not larger than 2GB, Otherwise set to False because of size limits imposed by Protocol Buffers.\n",
      "  warnings.warn(\"`use_external_data_format' is deprecated and ignored. Will be removed in next \"\n",
      "Validating ONNX model...\n",
      "\t-[✓] ONNX model output names match reference model ({'end_logits', 'start_logits'})\n",
      "\t- Validating ONNX Model output \"start_logits\":\n",
      "\t\t-[✓] (2, 8) matches (2, 8)\n",
      "\t\t-[✓] all values close (atol: 1e-05)\n",
      "\t- Validating ONNX Model output \"end_logits\":\n",
      "\t\t-[✓] (2, 8) matches (2, 8)\n",
      "\t\t-[✓] all values close (atol: 1e-05)\n",
      "All good, model saved at: bert-tiny-idiom-onnx/model.onnx\n"
     ]
    }
   ],
   "source": [
    "!python -m transformers.onnx --model=bert-tiny-idiom-finetuned --feature=question-answering bert-tiny-idiom-onnx"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Conclusion\n",
    "\n",
    "This tutorial shows how to use the Accuracy Estimator to simulate Envise conditions that evaluate the accuracy scores of a BERT-Tiny model.\n",
    "\n",
    "The results could vary slightly but are expected to stay in the range below:\n",
    "\n",
    "\n",
    "|   Eval type\t    |   EM score\t|\n",
    "|-------------------|---------------|\n",
    "|Out of the Box     |  48.5977  \t|\n",
    "|Envise w/no-tuning |  46.8037      |\n",
    "|One-epoch tuning   |  48.4629      |   \n",
    "\n",
    "\n",
    "If you fine-tune for more epochs, you could get better scores."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  },
  "vscode": {
   "interpreter": {
    "hash": "90eb5e0fcbf302e2fbb7d64d0f5d2fef12836215bc1f384012a2fbc863f866e5"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
